{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "31b2d207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1112, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SUB_ID</th>\n",
       "      <th>X</th>\n",
       "      <th>subject</th>\n",
       "      <th>SITE_ID</th>\n",
       "      <th>FILE_ID</th>\n",
       "      <th>DX_GROUP</th>\n",
       "      <th>anat_cnr</th>\n",
       "      <th>anat_efc</th>\n",
       "      <th>anat_fber</th>\n",
       "      <th>anat_fwhm</th>\n",
       "      <th>anat_qi1</th>\n",
       "      <th>anat_snr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>50002</td>\n",
       "      <td>1</td>\n",
       "      <td>50002</td>\n",
       "      <td>PITT</td>\n",
       "      <td>no_filename</td>\n",
       "      <td>1</td>\n",
       "      <td>10.201539</td>\n",
       "      <td>1.194664</td>\n",
       "      <td>16.223458</td>\n",
       "      <td>3.878000</td>\n",
       "      <td>0.152711</td>\n",
       "      <td>12.072452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>50003</td>\n",
       "      <td>2</td>\n",
       "      <td>50003</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050003</td>\n",
       "      <td>1</td>\n",
       "      <td>7.165701</td>\n",
       "      <td>1.126752</td>\n",
       "      <td>10.460008</td>\n",
       "      <td>4.282238</td>\n",
       "      <td>0.161716</td>\n",
       "      <td>9.241155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50004</td>\n",
       "      <td>3</td>\n",
       "      <td>50004</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050004</td>\n",
       "      <td>1</td>\n",
       "      <td>7.698144</td>\n",
       "      <td>1.226218</td>\n",
       "      <td>9.725750</td>\n",
       "      <td>3.881684</td>\n",
       "      <td>0.174186</td>\n",
       "      <td>9.323463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50005</td>\n",
       "      <td>4</td>\n",
       "      <td>50005</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050005</td>\n",
       "      <td>1</td>\n",
       "      <td>9.071807</td>\n",
       "      <td>1.256278</td>\n",
       "      <td>11.198226</td>\n",
       "      <td>3.628667</td>\n",
       "      <td>0.119269</td>\n",
       "      <td>10.814200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50006</td>\n",
       "      <td>5</td>\n",
       "      <td>50006</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050006</td>\n",
       "      <td>1</td>\n",
       "      <td>8.026798</td>\n",
       "      <td>1.407166</td>\n",
       "      <td>6.282055</td>\n",
       "      <td>3.674539</td>\n",
       "      <td>0.130647</td>\n",
       "      <td>10.123574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  SUB_ID  X  subject SITE_ID       FILE_ID  DX_GROUP   anat_cnr  \\\n",
       "0           1   50002  1    50002    PITT   no_filename         1  10.201539   \n",
       "1           2   50003  2    50003    PITT  Pitt_0050003         1   7.165701   \n",
       "2           3   50004  3    50004    PITT  Pitt_0050004         1   7.698144   \n",
       "3           4   50005  4    50005    PITT  Pitt_0050005         1   9.071807   \n",
       "4           5   50006  5    50006    PITT  Pitt_0050006         1   8.026798   \n",
       "\n",
       "   anat_efc  anat_fber  anat_fwhm  anat_qi1   anat_snr  \n",
       "0  1.194664  16.223458   3.878000  0.152711  12.072452  \n",
       "1  1.126752  10.460008   4.282238  0.161716   9.241155  \n",
       "2  1.226218   9.725750   3.881684  0.174186   9.323463  \n",
       "3  1.256278  11.198226   3.628667  0.119269  10.814200  \n",
       "4  1.407166   6.282055   3.674539  0.130647  10.123574  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('Phenotypic_V1_0b_preprocessed1.csv')\n",
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "39caed23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values:\n",
      "Unnamed: 0    0\n",
      "SUB_ID        0\n",
      "X             0\n",
      "subject       0\n",
      "SITE_ID       0\n",
      "FILE_ID       0\n",
      "DX_GROUP      0\n",
      "anat_cnr      0\n",
      "anat_efc      0\n",
      "anat_fber     0\n",
      "anat_fwhm     0\n",
      "anat_qi1      0\n",
      "anat_snr      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Dropping empty columns\n",
    "df['DX_GROUP'].replace(2, 0, inplace=True) #So sigmoid function gives right output. if you replace sigmoid, you can skip this\n",
    "\n",
    "df['anat_cnr'].replace('', np.nan, inplace=True)\n",
    "df['anat_efc'].replace('', np.nan, inplace=True)\n",
    "df['anat_fber'].replace('', np.nan, inplace=True)\n",
    "df['anat_fwhm'].replace('', np.nan, inplace=True)\n",
    "df['anat_qi1'].replace('', np.nan, inplace=True)\n",
    "df['anat_snr'].replace('', np.nan, inplace=True)\n",
    "\n",
    "#Replacing null values in all relevant input columns\n",
    "df.dropna(subset=['anat_cnr','anat_efc', 'anat_fber', 'anat_fwhm', 'anat_qi1', 'anat_snr'], inplace=True)\n",
    "\n",
    "#Verifying number of null rows\n",
    "print(\"Number of null values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "875e967c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training data samples:\n",
      "(653, 2016)\n"
     ]
    }
   ],
   "source": [
    "X = np.load(\"features.npz\")['a']\n",
    "y = np.load(\"labels.npz\")['a']\n",
    "y = np.select([y == 1, y == 2], [0, 1], y)\n",
    "\n",
    "train_x,test_x,train_y,test_y = train_test_split(X,y,random_state=42)\n",
    "print(\"\\nTraining data samples:\")\n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bc7a453c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled values of Train set \n",
      "\n",
      "[[0.62458682 0.25869528 0.77813539 ... 0.69973366 0.64220319 0.62623055]\n",
      " [0.36619258 0.15922842 0.55327651 ... 0.69319589 0.59513916 0.49256394]\n",
      " [0.44473889 0.55010733 0.29953039 ... 0.49220317 0.62189607 0.44785573]\n",
      " ...\n",
      " [0.69060952 0.77490686 0.76992131 ... 0.68014218 0.53279481 0.55429992]\n",
      " [0.63730504 0.43471942 0.68012454 ... 0.62819085 0.72711074 0.72213087]\n",
      " [0.9276913  0.7532871  0.6978907  ... 0.86303712 0.80951451 0.80104934]]\n",
      "\n",
      "Scaled values of Test set \n",
      "\n",
      "[[0.17371594 0.67910485 0.50993032 ... 0.71507732 0.69312968 0.82817554]\n",
      " [0.30584733 0.         0.48060218 ... 0.83418068 0.41021101 0.69783373]\n",
      " [0.57094588 0.63241503 0.93818587 ... 0.84096935 0.62120692 0.73941233]\n",
      " ...\n",
      " [0.3940889  0.69572294 0.48047557 ... 0.7169222  0.73136255 0.72531619]\n",
      " [0.20635841 0.22775244 0.58127283 ... 0.8653163  0.48998645 0.32111185]\n",
      " [0.48215526 0.68322656 0.52951599 ... 0.8790218  0.65768344 0.61489296]]\n",
      "\n",
      "Train set Tensors \n",
      "\n",
      "tensor([[0.6246, 0.2587, 0.7781,  ..., 0.6997, 0.6422, 0.6262],\n",
      "        [0.3662, 0.1592, 0.5533,  ..., 0.6932, 0.5951, 0.4926],\n",
      "        [0.4447, 0.5501, 0.2995,  ..., 0.4922, 0.6219, 0.4479],\n",
      "        ...,\n",
      "        [0.6906, 0.7749, 0.7699,  ..., 0.6801, 0.5328, 0.5543],\n",
      "        [0.6373, 0.4347, 0.6801,  ..., 0.6282, 0.7271, 0.7221],\n",
      "        [0.9277, 0.7533, 0.6979,  ..., 0.8630, 0.8095, 0.8010]])\n",
      "tensor([0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
      "        1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
      "        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1.,\n",
      "        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
      "        1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0.,\n",
      "        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,\n",
      "        0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
      "        1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 1.])\n",
      "\n",
      "Test set Tensors \n",
      "\n",
      "tensor([[0.1737, 0.6791, 0.5099,  ..., 0.7151, 0.6931, 0.8282],\n",
      "        [0.3058, 0.0000, 0.4806,  ..., 0.8342, 0.4102, 0.6978],\n",
      "        [0.5709, 0.6324, 0.9382,  ..., 0.8410, 0.6212, 0.7394],\n",
      "        ...,\n",
      "        [0.3941, 0.6957, 0.4805,  ..., 0.7169, 0.7314, 0.7253],\n",
      "        [0.2064, 0.2278, 0.5813,  ..., 0.8653, 0.4900, 0.3211],\n",
      "        [0.4822, 0.6832, 0.5295,  ..., 0.8790, 0.6577, 0.6149]])\n",
      "tensor([0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,\n",
      "        1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
      "        1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1.,\n",
      "        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
      "        0., 0.])\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import torch\n",
    "\n",
    "#MinMaxscaler is used to scale all the features of Train & Test dataframes\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "x_train = scaler.fit_transform(train_x)\n",
    "#x_test =  scaler.fit_transform(test_x.values)\n",
    "x_test =  scaler.fit_transform(test_x)\n",
    "\n",
    "print(\"Scaled values of Train set \\n\")\n",
    "print(x_train)\n",
    "print(\"\\nScaled values of Test set \\n\")\n",
    "print(x_test)\n",
    "\n",
    "#Train and Test sets are converted into Tensors\n",
    "x_tensor =  torch.from_numpy(x_train).float()\n",
    "y_tensor =  torch.from_numpy(train_y.ravel()).float()\n",
    "xtest_tensor =  torch.from_numpy(x_test).float()\n",
    "ytest_tensor =  torch.from_numpy(test_y.ravel()).float()\n",
    "\n",
    "print(\"\\nTrain set Tensors \\n\")\n",
    "print(x_tensor)\n",
    "print(y_tensor)\n",
    "print(\"\\nTest set Tensors \\n\")\n",
    "print(xtest_tensor)\n",
    "print(ytest_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ac05ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "#Define batch size \n",
    "bs = 64\n",
    "#x_train and y_train are combined to a single TensorDataset (easier to iterate over and slice)\n",
    "y_tensor = y_tensor.unsqueeze(1)\n",
    "train_ds = TensorDataset(x_tensor, y_tensor)\n",
    "#DataLoader is responsible for managing batches, & makes it easier to iterate over batches\n",
    "train_dl = DataLoader(train_ds, batch_size=bs)\n",
    "\n",
    "#For the validation/test dataset\n",
    "ytest_tensor = ytest_tensor.unsqueeze(1)\n",
    "test_ds = TensorDataset(xtest_tensor, ytest_tensor)\n",
    "test_loader = DataLoader(test_ds, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cef2adf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "n_input_dim = train_x.shape[1]\n",
    "#Layer size\n",
    "n_hidden1 = 3  # Number of hidden nodes\n",
    "n_hidden2 = 2\n",
    "n_output =  1   # Number of output nodes for binary classifier\n",
    "\n",
    "class ChurnModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChurnModel, self).__init__()\n",
    "        self.layer_1 = nn.Linear(n_input_dim, n_hidden1) \n",
    "        self.layer_2 = nn.Linear(n_hidden1, n_hidden2)\n",
    "        self.layer_out = nn.Linear(n_hidden2, n_output) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid() #outputs probability between 0 and 1\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(n_hidden1)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(n_hidden2)\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.sigmoid(self.layer_out(x))\n",
    "        return x\n",
    "    \n",
    "\n",
    "model = ChurnModel()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c190a6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss Computation\n",
    "loss_func = nn.BCELoss()\n",
    "#Optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.007, weight_decay= 1e-6)\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8535529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "train_loss, valid_loss = [], []\n",
    "for epoch in range(epochs):\n",
    "    #Within each epoch run the subsets of data = batch sizes.\n",
    "    for xb, yb in train_dl:\n",
    "        y_pred = model(xb)            # Forward Propagation\n",
    "        loss = loss_func(y_pred, yb)  # Loss Computation\n",
    "        optimizer.zero_grad()         # Clearing all previous gradients, setting to zero \n",
    "        loss.backward()               # Back Propagation\n",
    "        optimizer.step()              # Updating the parameters \n",
    "    train_loss.append(loss.item())\n",
    "    # evaluation part \n",
    "    model.eval()\n",
    "    for xb, yb in test_loader:\n",
    "        y_pred = model(xb)            # Forward Propagation\n",
    "        loss = loss_func(y_pred, yb)\n",
    "        valid_loss.append(loss.item())\n",
    "print (\"Epoch:\", epoch, \"Training Loss: \", np.mean(train_loss), \"Valid Loss: \", np.mean(valid_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd673ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "y_pred_list = []\n",
    "model.eval()\n",
    "#Model doesn't need to backpropagate the gradients in test set, so use torch.no_grad()\n",
    "#reduces memory usage and speeds up computation\n",
    "with torch.no_grad():\n",
    "    for xb_test,yb_test  in test_loader:\n",
    "        y_test_pred = model(xb_test)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.detach().numpy())\n",
    "\n",
    "#Takes arrays and makes them list of list for each batch        \n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "#flattens the lists in sequence\n",
    "ytest_pred = list(itertools.chain.from_iterable(y_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a451ce13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccb38c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(valid_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7368f8c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "#Classification accuracy\n",
    "y_true_test = test_y.ravel()\n",
    "print(metrics.classification_report(y_true_test,ytest_pred))\n",
    "\n",
    "print(\"Precision Score : \",precision_score(y_true_test,ytest_pred, pos_label='positive', average=None))\n",
    "print(\"Recall Score : \",recall_score(y_true_test,ytest_pred, pos_label='positive', average=None))\n",
    "print(\"F1 Score : \",f1_score(y_true_test,ytest_pred, pos_label='positive', average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bab9ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
