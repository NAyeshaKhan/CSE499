{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "31b2d207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1112, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SUB_ID</th>\n",
       "      <th>X</th>\n",
       "      <th>subject</th>\n",
       "      <th>SITE_ID</th>\n",
       "      <th>FILE_ID</th>\n",
       "      <th>DX_GROUP</th>\n",
       "      <th>anat_cnr</th>\n",
       "      <th>anat_efc</th>\n",
       "      <th>anat_fber</th>\n",
       "      <th>anat_fwhm</th>\n",
       "      <th>anat_qi1</th>\n",
       "      <th>anat_snr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>50002</td>\n",
       "      <td>1</td>\n",
       "      <td>50002</td>\n",
       "      <td>PITT</td>\n",
       "      <td>no_filename</td>\n",
       "      <td>1</td>\n",
       "      <td>10.201539</td>\n",
       "      <td>1.194664</td>\n",
       "      <td>16.223458</td>\n",
       "      <td>3.878000</td>\n",
       "      <td>0.152711</td>\n",
       "      <td>12.072452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>50003</td>\n",
       "      <td>2</td>\n",
       "      <td>50003</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050003</td>\n",
       "      <td>1</td>\n",
       "      <td>7.165701</td>\n",
       "      <td>1.126752</td>\n",
       "      <td>10.460008</td>\n",
       "      <td>4.282238</td>\n",
       "      <td>0.161716</td>\n",
       "      <td>9.241155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50004</td>\n",
       "      <td>3</td>\n",
       "      <td>50004</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050004</td>\n",
       "      <td>1</td>\n",
       "      <td>7.698144</td>\n",
       "      <td>1.226218</td>\n",
       "      <td>9.725750</td>\n",
       "      <td>3.881684</td>\n",
       "      <td>0.174186</td>\n",
       "      <td>9.323463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50005</td>\n",
       "      <td>4</td>\n",
       "      <td>50005</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050005</td>\n",
       "      <td>1</td>\n",
       "      <td>9.071807</td>\n",
       "      <td>1.256278</td>\n",
       "      <td>11.198226</td>\n",
       "      <td>3.628667</td>\n",
       "      <td>0.119269</td>\n",
       "      <td>10.814200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50006</td>\n",
       "      <td>5</td>\n",
       "      <td>50006</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050006</td>\n",
       "      <td>1</td>\n",
       "      <td>8.026798</td>\n",
       "      <td>1.407166</td>\n",
       "      <td>6.282055</td>\n",
       "      <td>3.674539</td>\n",
       "      <td>0.130647</td>\n",
       "      <td>10.123574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  SUB_ID  X  subject SITE_ID       FILE_ID  DX_GROUP   anat_cnr  \\\n",
       "0           1   50002  1    50002    PITT   no_filename         1  10.201539   \n",
       "1           2   50003  2    50003    PITT  Pitt_0050003         1   7.165701   \n",
       "2           3   50004  3    50004    PITT  Pitt_0050004         1   7.698144   \n",
       "3           4   50005  4    50005    PITT  Pitt_0050005         1   9.071807   \n",
       "4           5   50006  5    50006    PITT  Pitt_0050006         1   8.026798   \n",
       "\n",
       "   anat_efc  anat_fber  anat_fwhm  anat_qi1   anat_snr  \n",
       "0  1.194664  16.223458   3.878000  0.152711  12.072452  \n",
       "1  1.126752  10.460008   4.282238  0.161716   9.241155  \n",
       "2  1.226218   9.725750   3.881684  0.174186   9.323463  \n",
       "3  1.256278  11.198226   3.628667  0.119269  10.814200  \n",
       "4  1.407166   6.282055   3.674539  0.130647  10.123574  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('Phenotypic_V1_0b_preprocessed1.csv')\n",
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "39caed23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values:\n",
      "Unnamed: 0    0\n",
      "SUB_ID        0\n",
      "X             0\n",
      "subject       0\n",
      "SITE_ID       0\n",
      "FILE_ID       0\n",
      "DX_GROUP      0\n",
      "anat_cnr      0\n",
      "anat_efc      0\n",
      "anat_fber     0\n",
      "anat_fwhm     0\n",
      "anat_qi1      0\n",
      "anat_snr      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Dropping empty columns\n",
    "df['DX_GROUP'].replace(2, 0, inplace=True) #So sigmoid function gives right output. if you replace sigmoid, you can skip this\n",
    "\n",
    "df['anat_cnr'].replace('', np.nan, inplace=True)\n",
    "df['anat_efc'].replace('', np.nan, inplace=True)\n",
    "df['anat_fber'].replace('', np.nan, inplace=True)\n",
    "df['anat_fwhm'].replace('', np.nan, inplace=True)\n",
    "df['anat_qi1'].replace('', np.nan, inplace=True)\n",
    "df['anat_snr'].replace('', np.nan, inplace=True)\n",
    "\n",
    "#Replacing null values in all relevant input columns\n",
    "df.dropna(subset=['anat_cnr','anat_efc', 'anat_fber', 'anat_fwhm', 'anat_qi1', 'anat_snr'], inplace=True)\n",
    "\n",
    "#Verifying number of null rows\n",
    "print(\"Number of null values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "875e967c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training data samples:\n",
      "(824, 6)\n"
     ]
    }
   ],
   "source": [
    "X=df[['anat_cnr','anat_efc', 'anat_fber', 'anat_fwhm', 'anat_qi1', 'anat_snr']]\n",
    "y=df['DX_GROUP']\n",
    "\n",
    "train_x,test_x,train_y,test_y = train_test_split(X,y,random_state=42)\n",
    "print(\"\\nTraining data samples:\")\n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bc7a453c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled values of Train set \n",
      "\n",
      "[[2.66258512e-01 8.70834515e-01 5.95773557e-02 2.54271309e-01\n",
      "  1.26426844e-01 3.48438215e-03]\n",
      " [2.95043381e-01 8.70250262e-01 6.07201068e-02 1.92902434e-01\n",
      "  1.84607580e-01 2.87736912e-03]\n",
      " [2.21616507e-01 8.72967726e-01 1.99478635e-02 2.96678901e-01\n",
      "  2.40373774e-01 2.92762111e-03]\n",
      " ...\n",
      " [8.61828200e-02 6.96365784e-01 1.05786600e-01 4.53536588e-01\n",
      "  2.43836071e-01 1.95344244e-01]\n",
      " [5.72027934e-02 8.71470631e-01 6.19210410e-03 2.11209629e-01\n",
      "  4.03582689e-01 7.57881642e-04]\n",
      " [1.90426202e-01 9.26341194e-01 1.81483671e-03 6.57822767e-02\n",
      "  9.33983754e-01 1.53730773e-03]]\n",
      "\n",
      "Scaled values of Test set \n",
      "\n",
      "[[0.32057977 0.70368126 0.09093268 0.34956924 0.19662656 0.00928808]\n",
      " [0.1501252  0.29007592 0.37771861 0.44484029 0.42582975 0.81990578]\n",
      " [0.78950843 0.70594588 0.70125689 0.70093313 0.17442246 0.03957116]\n",
      " ...\n",
      " [0.486924   0.73549778 0.03119208 0.28398418 0.15877921 0.02604569]\n",
      " [0.26211649 0.72729547 0.00411507 0.74963734 0.257693   0.01229725]\n",
      " [0.22294218 0.70435568 0.03884201 0.30923219 0.2983811  0.00666926]]\n",
      "\n",
      "Train set Tensors \n",
      "\n",
      "tensor([[2.6626e-01, 8.7083e-01, 5.9577e-02, 2.5427e-01, 1.2643e-01, 3.4844e-03],\n",
      "        [2.9504e-01, 8.7025e-01, 6.0720e-02, 1.9290e-01, 1.8461e-01, 2.8774e-03],\n",
      "        [2.2162e-01, 8.7297e-01, 1.9948e-02, 2.9668e-01, 2.4037e-01, 2.9276e-03],\n",
      "        ...,\n",
      "        [8.6183e-02, 6.9637e-01, 1.0579e-01, 4.5354e-01, 2.4384e-01, 1.9534e-01],\n",
      "        [5.7203e-02, 8.7147e-01, 6.1921e-03, 2.1121e-01, 4.0358e-01, 7.5788e-04],\n",
      "        [1.9043e-01, 9.2634e-01, 1.8148e-03, 6.5782e-02, 9.3398e-01, 1.5373e-03]])\n",
      "tensor([0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,\n",
      "        0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
      "        1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
      "        0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,\n",
      "        0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
      "        1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0.,\n",
      "        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,\n",
      "        0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
      "        1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0.])\n",
      "\n",
      "Test set Tensors \n",
      "\n",
      "tensor([[0.3206, 0.7037, 0.0909, 0.3496, 0.1966, 0.0093],\n",
      "        [0.1501, 0.2901, 0.3777, 0.4448, 0.4258, 0.8199],\n",
      "        [0.7895, 0.7059, 0.7013, 0.7009, 0.1744, 0.0396],\n",
      "        ...,\n",
      "        [0.4869, 0.7355, 0.0312, 0.2840, 0.1588, 0.0260],\n",
      "        [0.2621, 0.7273, 0.0041, 0.7496, 0.2577, 0.0123],\n",
      "        [0.2229, 0.7044, 0.0388, 0.3092, 0.2984, 0.0067]])\n",
      "tensor([1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
      "        1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1.,\n",
      "        0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
      "        1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
      "        0., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import torch\n",
    "\n",
    "#MinMaxscaler is used to scale all the features of Train & Test dataframes\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "x_train = scaler.fit_transform(train_x.values)\n",
    "x_test =  scaler.fit_transform(test_x.values)\n",
    "\n",
    "print(\"Scaled values of Train set \\n\")\n",
    "print(x_train)\n",
    "print(\"\\nScaled values of Test set \\n\")\n",
    "print(x_test)\n",
    "\n",
    "#Train and Test sets are converted into Tensors\n",
    "x_tensor =  torch.from_numpy(x_train).float()\n",
    "y_tensor =  torch.from_numpy(train_y.values.ravel()).float()\n",
    "xtest_tensor =  torch.from_numpy(x_test).float()\n",
    "ytest_tensor =  torch.from_numpy(test_y.values.ravel()).float()\n",
    "\n",
    "print(\"\\nTrain set Tensors \\n\")\n",
    "print(x_tensor)\n",
    "print(y_tensor)\n",
    "print(\"\\nTest set Tensors \\n\")\n",
    "print(xtest_tensor)\n",
    "print(ytest_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "05ac05ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "#Define batch size \n",
    "bs = 64\n",
    "#x_train and y_train are combined to a single TensorDataset (easier to iterate over and slice)\n",
    "y_tensor = y_tensor.unsqueeze(1)\n",
    "train_ds = TensorDataset(x_tensor, y_tensor)\n",
    "#DataLoader is responsible for managing batches, & makes it easier to iterate over batches\n",
    "train_dl = DataLoader(train_ds, batch_size=bs)\n",
    "\n",
    "#For the validation/test dataset\n",
    "ytest_tensor = ytest_tensor.unsqueeze(1)\n",
    "test_ds = TensorDataset(xtest_tensor, ytest_tensor)\n",
    "test_loader = DataLoader(test_ds, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6cef2adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChurnModel(\n",
      "  (layer_1): Linear(in_features=6, out_features=300, bias=True)\n",
      "  (layer_2): Linear(in_features=300, out_features=75, bias=True)\n",
      "  (layer_out): Linear(in_features=75, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (batchnorm1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm1d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "n_input_dim = train_x.shape[1]\n",
    "#Layer size\n",
    "n_hidden1 = 300  # Number of hidden nodes\n",
    "n_hidden2 = 75\n",
    "n_output =  1   # Number of output nodes for binary classifier\n",
    "\n",
    "class ChurnModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChurnModel, self).__init__()\n",
    "        self.layer_1 = nn.Linear(n_input_dim, n_hidden1) \n",
    "        self.layer_2 = nn.Linear(n_hidden1, n_hidden2)\n",
    "        self.layer_out = nn.Linear(n_hidden2, n_output) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid() #outputs probability between 0 and 1\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(n_hidden1)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(n_hidden2)\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.sigmoid(self.layer_out(x))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "model = ChurnModel()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c190a6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss Computation\n",
    "loss_func = nn.BCELoss()\n",
    "#Optimizer\n",
    "learning_rate = 0.0007\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "epochs = 130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8535529e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last iteration loss value: 0.2914283275604248\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "train_loss = []\n",
    "for epoch in range(epochs):\n",
    "    #Within each epoch run the subsets of data = batch sizes.\n",
    "    for xb, yb in train_dl:\n",
    "        y_pred = model(xb)            # Forward Propagation\n",
    "        loss = loss_func(y_pred, yb)  # Loss Computation\n",
    "        optimizer.zero_grad()         # Clearing all previous gradients, setting to zero \n",
    "        loss.backward()               # Back Propagation\n",
    "        optimizer.step()              # Updating the parameters \n",
    "    #print(\"Loss in iteration :\"+str(epoch)+\" is: \"+str(loss.item()))\n",
    "    train_loss.append(loss.item())\n",
    "print('Last iteration loss value: '+str(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a451ce13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9dd673ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "y_pred_list = []\n",
    "model.eval()\n",
    "#Model doesn't need to backpropagate the gradients in test set, so use torch.no_grad()\n",
    "#reduces memory usage and speeds up computation\n",
    "with torch.no_grad():\n",
    "    for xb_test,yb_test  in test_loader:\n",
    "        y_test_pred = model(xb_test)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.detach().numpy())\n",
    "\n",
    "#Takes arrays and makes them list of list for each batch        \n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "#flattens the lists in sequence\n",
    "ytest_pred = list(itertools.chain.from_iterable(y_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7368f8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.37      0.44       152\n",
      "           1       0.45      0.63      0.52       123\n",
      "\n",
      "    accuracy                           0.48       275\n",
      "   macro avg       0.50      0.50      0.48       275\n",
      "weighted avg       0.50      0.48      0.48       275\n",
      "\n",
      "Confusion Matrix of the Test Set:\n",
      "[[56 96]\n",
      " [46 77]]\n",
      "Precision Score :  [0.54901961 0.44508671]\n",
      "Recall Score :  [0.36842105 0.62601626]\n",
      "F1 Score :  [0.44094488 0.52027027]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1370: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got None). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1370: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got None). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1370: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got None). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "#Classification accuracy\n",
    "y_true_test = test_y.values.ravel()\n",
    "print(metrics.classification_report(y_true_test,ytest_pred))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true_test ,ytest_pred)\n",
    "print(\"Confusion Matrix of the Test Set:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"Precision Score : \",precision_score(y_true_test,ytest_pred, pos_label='positive', average=None))\n",
    "print(\"Recall Score : \",recall_score(y_true_test,ytest_pred, pos_label='positive', average=None))\n",
    "print(\"F1 Score : \",f1_score(y_true_test,ytest_pred, pos_label='positive', average=None))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
