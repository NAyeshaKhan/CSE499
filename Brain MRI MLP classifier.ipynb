{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "31b2d207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1112, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SUB_ID</th>\n",
       "      <th>X</th>\n",
       "      <th>subject</th>\n",
       "      <th>SITE_ID</th>\n",
       "      <th>FILE_ID</th>\n",
       "      <th>DX_GROUP</th>\n",
       "      <th>anat_cnr</th>\n",
       "      <th>anat_efc</th>\n",
       "      <th>anat_fber</th>\n",
       "      <th>anat_fwhm</th>\n",
       "      <th>anat_qi1</th>\n",
       "      <th>anat_snr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>50002</td>\n",
       "      <td>1</td>\n",
       "      <td>50002</td>\n",
       "      <td>PITT</td>\n",
       "      <td>no_filename</td>\n",
       "      <td>1</td>\n",
       "      <td>10.201539</td>\n",
       "      <td>1.194664</td>\n",
       "      <td>16.223458</td>\n",
       "      <td>3.878000</td>\n",
       "      <td>0.152711</td>\n",
       "      <td>12.072452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>50003</td>\n",
       "      <td>2</td>\n",
       "      <td>50003</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050003</td>\n",
       "      <td>1</td>\n",
       "      <td>7.165701</td>\n",
       "      <td>1.126752</td>\n",
       "      <td>10.460008</td>\n",
       "      <td>4.282238</td>\n",
       "      <td>0.161716</td>\n",
       "      <td>9.241155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50004</td>\n",
       "      <td>3</td>\n",
       "      <td>50004</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050004</td>\n",
       "      <td>1</td>\n",
       "      <td>7.698144</td>\n",
       "      <td>1.226218</td>\n",
       "      <td>9.725750</td>\n",
       "      <td>3.881684</td>\n",
       "      <td>0.174186</td>\n",
       "      <td>9.323463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50005</td>\n",
       "      <td>4</td>\n",
       "      <td>50005</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050005</td>\n",
       "      <td>1</td>\n",
       "      <td>9.071807</td>\n",
       "      <td>1.256278</td>\n",
       "      <td>11.198226</td>\n",
       "      <td>3.628667</td>\n",
       "      <td>0.119269</td>\n",
       "      <td>10.814200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50006</td>\n",
       "      <td>5</td>\n",
       "      <td>50006</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050006</td>\n",
       "      <td>1</td>\n",
       "      <td>8.026798</td>\n",
       "      <td>1.407166</td>\n",
       "      <td>6.282055</td>\n",
       "      <td>3.674539</td>\n",
       "      <td>0.130647</td>\n",
       "      <td>10.123574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  SUB_ID  X  subject SITE_ID       FILE_ID  DX_GROUP   anat_cnr  \\\n",
       "0           1   50002  1    50002    PITT   no_filename         1  10.201539   \n",
       "1           2   50003  2    50003    PITT  Pitt_0050003         1   7.165701   \n",
       "2           3   50004  3    50004    PITT  Pitt_0050004         1   7.698144   \n",
       "3           4   50005  4    50005    PITT  Pitt_0050005         1   9.071807   \n",
       "4           5   50006  5    50006    PITT  Pitt_0050006         1   8.026798   \n",
       "\n",
       "   anat_efc  anat_fber  anat_fwhm  anat_qi1   anat_snr  \n",
       "0  1.194664  16.223458   3.878000  0.152711  12.072452  \n",
       "1  1.126752  10.460008   4.282238  0.161716   9.241155  \n",
       "2  1.226218   9.725750   3.881684  0.174186   9.323463  \n",
       "3  1.256278  11.198226   3.628667  0.119269  10.814200  \n",
       "4  1.407166   6.282055   3.674539  0.130647  10.123574  "
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('Phenotypic_V1_0b_preprocessed1.csv')\n",
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "39caed23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values:\n",
      "Unnamed: 0    0\n",
      "SUB_ID        0\n",
      "X             0\n",
      "subject       0\n",
      "SITE_ID       0\n",
      "FILE_ID       0\n",
      "DX_GROUP      0\n",
      "anat_cnr      0\n",
      "anat_efc      0\n",
      "anat_fber     0\n",
      "anat_fwhm     0\n",
      "anat_qi1      0\n",
      "anat_snr      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Dropping empty columns\n",
    "df['DX_GROUP'].replace(2, 0, inplace=True) #So sigmoid function gives right output. if you replace sigmoid, you can skip this\n",
    "\n",
    "df['anat_cnr'].replace('', np.nan, inplace=True)\n",
    "df['anat_efc'].replace('', np.nan, inplace=True)\n",
    "df['anat_fber'].replace('', np.nan, inplace=True)\n",
    "df['anat_fwhm'].replace('', np.nan, inplace=True)\n",
    "df['anat_qi1'].replace('', np.nan, inplace=True)\n",
    "df['anat_snr'].replace('', np.nan, inplace=True)\n",
    "\n",
    "#Replacing null values in all relevant input columns\n",
    "df.dropna(subset=['anat_cnr','anat_efc', 'anat_fber', 'anat_fwhm', 'anat_qi1', 'anat_snr'], inplace=True)\n",
    "\n",
    "#Verifying number of null rows\n",
    "print(\"Number of null values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "875e967c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training data samples:\n",
      "(824, 6)\n"
     ]
    }
   ],
   "source": [
    "X=df[['anat_cnr','anat_efc', 'anat_fber', 'anat_fwhm', 'anat_qi1', 'anat_snr']]\n",
    "y=df['DX_GROUP']\n",
    "\n",
    "train_x,test_x,train_y,test_y = train_test_split(X,y,random_state=42)\n",
    "print(\"\\nTraining data samples:\")\n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "bc7a453c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled values of Train set \n",
      "\n",
      "[[2.66258512e-01 8.70834515e-01 5.95773557e-02 2.54271309e-01\n",
      "  1.26426844e-01 3.48438215e-03]\n",
      " [2.95043381e-01 8.70250262e-01 6.07201068e-02 1.92902434e-01\n",
      "  1.84607580e-01 2.87736912e-03]\n",
      " [2.21616507e-01 8.72967726e-01 1.99478635e-02 2.96678901e-01\n",
      "  2.40373774e-01 2.92762111e-03]\n",
      " ...\n",
      " [8.61828200e-02 6.96365784e-01 1.05786600e-01 4.53536588e-01\n",
      "  2.43836071e-01 1.95344244e-01]\n",
      " [5.72027934e-02 8.71470631e-01 6.19210410e-03 2.11209629e-01\n",
      "  4.03582689e-01 7.57881642e-04]\n",
      " [1.90426202e-01 9.26341194e-01 1.81483671e-03 6.57822767e-02\n",
      "  9.33983754e-01 1.53730773e-03]]\n",
      "\n",
      "Scaled values of Test set \n",
      "\n",
      "[[0.32057977 0.70368126 0.09093268 0.34956924 0.19662656 0.00928808]\n",
      " [0.1501252  0.29007592 0.37771861 0.44484029 0.42582975 0.81990578]\n",
      " [0.78950843 0.70594588 0.70125689 0.70093313 0.17442246 0.03957116]\n",
      " ...\n",
      " [0.486924   0.73549778 0.03119208 0.28398418 0.15877921 0.02604569]\n",
      " [0.26211649 0.72729547 0.00411507 0.74963734 0.257693   0.01229725]\n",
      " [0.22294218 0.70435568 0.03884201 0.30923219 0.2983811  0.00666926]]\n",
      "\n",
      "Train set Tensors \n",
      "\n",
      "tensor([[2.6626e-01, 8.7083e-01, 5.9577e-02, 2.5427e-01, 1.2643e-01, 3.4844e-03],\n",
      "        [2.9504e-01, 8.7025e-01, 6.0720e-02, 1.9290e-01, 1.8461e-01, 2.8774e-03],\n",
      "        [2.2162e-01, 8.7297e-01, 1.9948e-02, 2.9668e-01, 2.4037e-01, 2.9276e-03],\n",
      "        ...,\n",
      "        [8.6183e-02, 6.9637e-01, 1.0579e-01, 4.5354e-01, 2.4384e-01, 1.9534e-01],\n",
      "        [5.7203e-02, 8.7147e-01, 6.1921e-03, 2.1121e-01, 4.0358e-01, 7.5788e-04],\n",
      "        [1.9043e-01, 9.2634e-01, 1.8148e-03, 6.5782e-02, 9.3398e-01, 1.5373e-03]])\n",
      "tensor([0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,\n",
      "        0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
      "        1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
      "        0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,\n",
      "        0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
      "        1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0.,\n",
      "        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,\n",
      "        0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
      "        1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0.])\n",
      "\n",
      "Test set Tensors \n",
      "\n",
      "tensor([[0.3206, 0.7037, 0.0909, 0.3496, 0.1966, 0.0093],\n",
      "        [0.1501, 0.2901, 0.3777, 0.4448, 0.4258, 0.8199],\n",
      "        [0.7895, 0.7059, 0.7013, 0.7009, 0.1744, 0.0396],\n",
      "        ...,\n",
      "        [0.4869, 0.7355, 0.0312, 0.2840, 0.1588, 0.0260],\n",
      "        [0.2621, 0.7273, 0.0041, 0.7496, 0.2577, 0.0123],\n",
      "        [0.2229, 0.7044, 0.0388, 0.3092, 0.2984, 0.0067]])\n",
      "tensor([1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
      "        1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1.,\n",
      "        0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
      "        1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
      "        0., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import torch\n",
    "\n",
    "#MinMaxscaler is used to scale all the features of Train & Test dataframes\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "x_train = scaler.fit_transform(train_x.values)\n",
    "x_test =  scaler.fit_transform(test_x.values)\n",
    "\n",
    "print(\"Scaled values of Train set \\n\")\n",
    "print(x_train)\n",
    "print(\"\\nScaled values of Test set \\n\")\n",
    "print(x_test)\n",
    "\n",
    "#Train and Test sets are converted into Tensors\n",
    "x_tensor =  torch.from_numpy(x_train).float()\n",
    "y_tensor =  torch.from_numpy(train_y.values.ravel()).float()\n",
    "xtest_tensor =  torch.from_numpy(x_test).float()\n",
    "ytest_tensor =  torch.from_numpy(test_y.values.ravel()).float()\n",
    "\n",
    "print(\"\\nTrain set Tensors \\n\")\n",
    "print(x_tensor)\n",
    "print(y_tensor)\n",
    "print(\"\\nTest set Tensors \\n\")\n",
    "print(xtest_tensor)\n",
    "print(ytest_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "05ac05ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "#Define batch size \n",
    "bs = 64\n",
    "#x_train and y_train are combined to a single TensorDataset (easier to iterate over and slice)\n",
    "y_tensor = y_tensor.unsqueeze(1)\n",
    "train_ds = TensorDataset(x_tensor, y_tensor)\n",
    "#DataLoader is responsible for managing batches, & makes it easier to iterate over batches\n",
    "train_dl = DataLoader(train_ds, batch_size=bs)\n",
    "\n",
    "#For the validation/test dataset\n",
    "ytest_tensor = ytest_tensor.unsqueeze(1)\n",
    "test_ds = TensorDataset(xtest_tensor, ytest_tensor)\n",
    "test_loader = DataLoader(test_ds, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "6cef2adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChurnModel(\n",
      "  (layer_1): Linear(in_features=6, out_features=2, bias=True)\n",
      "  (layer_2): Linear(in_features=2, out_features=1, bias=True)\n",
      "  (layer_out): Linear(in_features=1, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (batchnorm1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "n_input_dim = train_x.shape[1]\n",
    "#Layer size\n",
    "n_hidden1 = 2  # Number of hidden nodes\n",
    "n_hidden2 = 1\n",
    "n_output =  1   # Number of output nodes for binary classifier\n",
    "\n",
    "class ChurnModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChurnModel, self).__init__()\n",
    "        self.layer_1 = nn.Linear(n_input_dim, n_hidden1) \n",
    "        self.layer_2 = nn.Linear(n_hidden1, n_hidden2)\n",
    "        self.layer_out = nn.Linear(n_hidden2, n_output) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid() #outputs probability between 0 and 1\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(n_hidden1)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(n_hidden2)\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.sigmoid(self.layer_out(x))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "model = ChurnModel()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "c190a6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss Computation\n",
    "loss_func = nn.BCELoss()\n",
    "#Optimizer\n",
    "learning_rate = 0.0007\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "epochs = 130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "8535529e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last iteration loss value: 0.6803673505783081\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "train_loss = []\n",
    "for epoch in range(epochs):\n",
    "    #Within each epoch run the subsets of data = batch sizes.\n",
    "    for xb, yb in train_dl:\n",
    "        y_pred = model(xb)            # Forward Propagation\n",
    "        loss = loss_func(y_pred, yb)  # Loss Computation\n",
    "        optimizer.zero_grad()         # Clearing all previous gradients, setting to zero \n",
    "        loss.backward()               # Back Propagation\n",
    "        optimizer.step()              # Updating the parameters \n",
    "    #print(\"Loss in iteration :\"+str(epoch)+\" is: \"+str(loss.item()))\n",
    "    train_loss.append(loss.item())\n",
    "print('Last iteration loss value: '+str(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "a451ce13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA6kklEQVR4nO3deXzdVZ3/8dfn3uRm3/etTdImTdMdQilLqZZdEFxQijOgMwo6o6jMjDM4+nPBGWccFwTEGXEZB0EqAkpRsEKLrKU03fc06Zak2fd9u+f3x11yk9zk3qZJbnLzeT4eedD7vd+be+6lfd9zP2f5ijEGpZRSwcsS6AYopZSaXhr0SikV5DTolVIqyGnQK6VUkNOgV0qpIBcS6AaMlpycbHJzcwPdDKWUmlN2797daIxJ8XbfrAv63NxcSktLA90MpZSaU0TkzHj3aelGKaWCnAa9UkoFOQ16pZQKchr0SikV5DTolVIqyGnQK6VUkNOgV0qpIBeUQV96upnS082BboZSSs0KQRf0z+6u4vbH3uEzT+ymf9Ae6OYopVTABVXQ/+9bp/jH3+5nQWIkjZ39bD9WF+gmKaVUwAVN0JfXd/KtPxzh+mVpvPj59aTHhvObXZWBbpZSSgXcrNvrZrIWp0bz1N3ruHhhAiFWC7ddnM2P/1LOudYeMuMjAt08pZQKGL969CJyg4gcF5FyEbnfy/0Pisg+50+ZiLR63PdfInJYRI6KyMMiIlPY/hEuzU8ixOp4SR8tycFu4JndVdP1dEopNSf4DHoRsQKPAjcCxcAdIlLseY4x5j5jzGpjzGrgEeA552MvB64AVgLLgUuADVP5AsazICmSyxcl8XRpJXa7XgBdKTV/+dOjXwuUG2NOGmP6gc3ArROcfwfwlPPPBggHbEAYEArM2AjpR0tyqGrpYW9ly0w9pVJKzTr+BH0W4DmqWeU8NoaILATygO0AxpgdwKtAjfNnqzHmqJfH3SMipSJS2tDQcH6vYALvLUrFahG2Ha2fst+plFJzzVTPutkEPGOMGQIQkcXAUiAbx4fDRhFZP/pBxpjHjDElxpiSlBSvF0iZlLiIUC7JTdCgV0rNa/4EfTWQ43E723nMm00Ml20APgi8Y4zpNMZ0Ai8Bl02moZN1zdI0jtd1UNncPZNPq5RSs4Y/Qb8LKBCRPBGx4QjzLaNPEpEiIAHY4XH4LLBBREJEJBTHQOyY0s102liUCsD2Y9qrV0rNTz6D3hgzCHwO2IojpJ82xhwWkQdE5BaPUzcBm40xnlNcngEqgIPAfmC/MeaFKWu9H/JToslPjmKbBr1Sap7ya8GUMeZF4MVRx7426vY3vDxuCPj0BbRvSmwsSuXxHWfo7BskOixo1ogppZRfgmYLhIlcvTSN/iE7b56Yuhk9Sik1V8yLoC/JTSAmLITXyhoD3RSllJpx8yLoQ60WLs1P5O0KDXql1PwzL4Ie4PJFyZxp6qaqRadZKqXml3kT9FcsTgbg7YqmALdEKaVm1rwJ+sK0aJKjw3i7XMs3Sqn5Zd4EvYhw+aIk3qpoYuRUf6WUCm7zJugBLl+URENHH+X1nYFuilJKzZh5FfRap1dKzUfzKuhzEiPJSYzgLa3TK6XmkXkV9ADrC1J4q7yR3oGhQDdFKaVmxLwL+uuXpdPVP8SbJ7RXr5SaH+Zd0F+Wn0RseAgvHaoNdFOUUmpGzLugt4VYuKY4jVeO1jEwZA90c5RSatrNu6AHuHF5Bm09A+zQ2TdKqXlgXgb9+oJkomxWXjpUE+imKKXUtJuXQR8eauW9Ran8+XAdQ3ZdJauUCm7zMugB3rcig6aufrYe1kFZpVRwm7dBf11xGoVp0fznS8foG9Q59Uqp4DVvgz7EauErNxVztrmbx98+E+jmKKXUtJm3QQ+woTCF9yxJ4eHtJ2jq7At0c5RSalrM66AH+OpNS+nuH+K7W48HuilKKTUt5n3QL06N4VNX5rF5V6Vui6CUCkrzPugB7ru2kPzkKP7l2QN09g0GujlKKTWlNOhxzKv/7kdWcq6th++8dCzQzVFKqSmlQe908cJEPn5ZLk/sPMORc+2Bbo5SSk0ZDXoP911TSGx4KP/x0tFAN0UppaaMX0EvIjeIyHERKReR+73c/6CI7HP+lIlIq8d9C0TkzyJyVESOiEju1DV/asVFhnLvxsW8caKR18saAt0cpZSaEj6DXkSswKPAjUAxcIeIFHueY4y5zxiz2hizGngEeM7j7seB7xpjlgJrgfopavu0uPOyheQkRvDtF4/qPjhKqaDgT49+LVBujDlpjOkHNgO3TnD+HcBTAM4PhBBjzMsAxphOY0z3BbZ5WoWFWPnn64s4VtvBj18tD3RzlFLqgvkT9FlApcftKuexMURkIZAHbHceKgRaReQ5EdkrIt91fkOY1W5emcGH1mTx/ZfLeOmgbmWslJrbpnowdhPwjDHGtUtYCLAe+CfgEiAf+MToB4nIPSJSKiKlDQ2Br42LCN/+0AouWhDPfU/v41B124j769p7sWtZRyk1R/gT9NVAjsftbOcxbzbhLNs4VQH7nGWfQeD3wEWjH2SMecwYU2KMKUlJSfGr4dMtPNTKT+4sISkqjE/9Xyn17b0APL+vmku/vY0/ak9fKTVH+BP0u4ACEckTERuOMN8y+iQRKQISgB2jHhsvIq703ggcubAmz5yUmDB+9vES2nsHuPvxUrYfq+OffrsfgNLTzQFunVJK+cdn0Dt74p8DtgJHgaeNMYdF5AERucXj1E3AZmOM8XjsEI6yzTYROQgI8NOpfAHTbWlGLA9tWsOB6jb+9pel5CdHsywzloOjyjlKKTVbiUcuzwolJSWmtLQ00M0Y45dvneLZPdU8dtfF/PT1U/z63TMc+sb1hFh1zZlSKvBEZLcxpsTbfZpSfvrEFXm8cO+VZMRFsCI7lt4BOxUNXYFullJK+aRBPwkrsuIAtHyjlJoTNOgnIS85mkiblYNVrYFuilJK+aRBPwlWi+iArFJqztCgn6TlWXEcqWlncMge6KYopdSENOgnaUVWnA7IKqXmBA36SdIBWaXUXKFBP0n5KY4B2VeP1VNW10HvwJDvBymlVACEBLoBc5XVIpTkJvLHgzX88WAN8ZGhPPOZy1icGhPopiml1Ajao78Aj915Mb//7BU8tGk1FhHufWqf9uyVUrOOBv0FCA+1sjonnltXZ/G9j6zkaE073/nTsUA3SymlRtDSzRTZWJTG31yRy/++dZrW7gEuyU3k2uI0UmLCAt00pdQ8p0E/he6/sYj2nkH+crye3+2t5vEdp3npC+sRkUA3TSk1j2nQT6GwECvf/+gqjDH8/M1T/Nsfj1Je30lBmg7QKqUCR2v000BEuGVVJiLwp0O1gW6OUmqe06CfJqmx4azJiedPhzXolVKBpUE/jW5Yns7hc+1UNncHuilKqXlMg34aXb8sHYCt2qtXSgWQBv00WpgURVF6jAa9UiqgNOin2Q3L0yk908JXf3+Ql4/U0TeoK2eVUjNLp1dOszvXLeRoTTvP7anmiXfOsjQjlkc/tob8lOhAN00pNU9oj36aJUWH8ZM7S9j3tev48V9dRG1bD+9/5E3+eKAm0E1TSs0TGvQzxBZi4X0rMnjxC+tZkh7DF3+zl7K6jkA3Syk1D2jQz7CMuAh+elcJ0WEhfPm5g9jtJtBNUkoFOQ36AEiKDuOrNxWz+0wLT+48E+jmKKWCnAZ9gHzooizWFyTznT8dp6GjL9DNUUoFMQ36ABER/vn6Ijr7Bnm7ojHQzVFKBTEN+gBamhFDWIiFQ3qBcaXUNPIr6EXkBhE5LiLlInK/l/sfFJF9zp8yEWkddX+siFSJyI+mqN1BIcRqoSgjlkPV7YFuilIqiPlcMCUiVuBR4FqgCtglIluMMUdc5xhj7vM4/15gzahf8y3g9SlpcZBZnhnLlv3nMMboBUqUUtPCnx79WqDcGHPSGNMPbAZuneD8O4CnXDdE5GIgDfjzhTQ0WC3PiqOjd5DK5p5AN0UpFaT8CfosoNLjdpXz2BgishDIA7Y7b1uA7wP/NNETiMg9IlIqIqUNDQ3+tDtoLM+MA+DQOa3TK6Wmx1QPxm4CnjHGuHbu+nvgRWNM1UQPMsY8ZowpMcaUpKSkTHGTZrfC9GhCLMJhDXql1DTxZ1OzaiDH43a285g3m4DPety+DFgvIn8PRAM2Eek0xowZ0J2vwkKsFKbF6ICsUmra+NOj3wUUiEieiNhwhPmW0SeJSBGQAOxwHTPG/JUxZoExJhdH+eZxDfmxlmXGcqi6DWMMz+6u4u+f3M3AkD3QzVJKBQmfQW+MGQQ+B2wFjgJPG2MOi8gDInKLx6mbgM3GGN285Twtz4qjqauf7cfq+fJzB3nxYC2P79CtEZRSU0NmWy6XlJSY0tLSQDdjRu0+08yH/3sH4aEW4iJCyU2K4si5dl790ntIjg4LdPOUUnOAiOw2xpR4u09Xxs4CSzNiEYG+QTs/vH0N//7BFfQMDPG9rccD3TSlVBDQK0zNApG2ED58UTZF6TFctigJgI9fnssv3jrFu6ea6R0Y4o61C7j36oIAt1QpNRdp0M8S3/vIqhG3v3hNAX2DQ7R2D1BW18HP3jzFpzcswhaiX8KUUudHU2OWigkP5d8+sIIffewi7r+xiLaeAV4vG15M1tk3iK/xld6BIbr7B6e7qUqpWU6Dfg64cnEK8ZGhvHDgHADHazu4+Fsv88eD3q87W9HQydeeP8Ql//YKH/vpzplsqlJqFtKgnwNsIRZuXJ7Oy0fq6O4f5JsvHKZv0M6BqrGraXsHhvjgo2+xeVclSdE2Dla30Tc45OW3KqXmCw36OeL9qzLp7h/i/mcP8nZFEyJwsqFrzHmnm7po7x3ku7et5B+vW8KQ3Xg9Tyk1f+hg7BxxaV4SqTFhbNl/jqL0GLITIjnZ2DnmvIp6R6gXpMYQYnVse3y8toOlGbEz2l6l1OyhPfo5wmoR3r8qE4Cvvb+YgrRozjZ1Mzhqq4SKBkf45yVHkZccRahVOF7XMePtVUrNHtqjn0M+v7GADYUpXL4omeqWHgbthqqWHnKTo9znnGzoJCs+ggibFYBFKdGU1WrQKzWfaY9+DomLDOWqQsc2zvkpjnAfXb6paOhiUWq0+3ZhWoz26JWa5zTo56i8ZEeYew60GmOoaOhkUcpwD39JegxVLT109ul8eqXmKw36OSoxykZ8ZCinGoeDvra9l+7+IfJTRvboAcq0V6/UvKVBP4flJUeN6NG7Ztx49uiL0p1Br3V6peYtDfo5LC85akSP3lWvX+zRo8+KjyDSZuWYBr1S85YG/Ry2KCWa2vZeupz194r6TqLDQkiJGd7D3mIRCtJitHSj1DymQT+H5TmnVZ5ucvTqKxq6WJQShYiMOK9Ig16peU2Dfg5zBb2rTu+YcRM95rzC9BgaO/tp7Oyb0fYppWYHDfo5zBX0pxq76OobpKatd8QcepfCNMexE3Vjt0xQSgU/Dfo5LDzUSlZ8BKVnWtx71ed7rJJ1cU239LY3jlIq+OkWCHPcyuw4XjpU6w56bz36jNhwwkMtuoulUvOUBv0c99CmNfxdbTvl9Z30Ddop8BL0FouQlxzNyQbt0Ss1H2nQz3G2EAsrs+NZmR0/4Xn5KVEcqh57oRKlVPDTGv08sSg5isrmbr3alFLzkAb9PJGfEo3dwNmm7kA3RSk1wzTo5wnXtsYVOiCr1LyjQT9PuBdX6RRLpeYdv4JeRG4QkeMiUi4i93u5/0ER2ef8KRORVufx1SKyQ0QOi8gBEbl9ituv/BQTHkpqTJhOsVRqHvI560ZErMCjwLVAFbBLRLYYY464zjHG3Odx/r3AGufNbuAuY8wJEckEdovIVmNM6xS+BuWn/JQonWKp1DzkT49+LVBujDlpjOkHNgO3TnD+HcBTAMaYMmPMCeefzwH1QMqFNVlNVn5KNCcbtUev1HzjT9BnAZUet6ucx8YQkYVAHrDdy31rARtQ4eW+e0SkVERKGxoa/Gm3moT85Chauwdo7uoPdFOUUjNoqgdjNwHPGGNGTNYWkQzgV8DfGGPsox9kjHnMGFNijClJSdEO/3Rx7Wx5rLadrz9/iDt/vpP+wTH/O5RSQcafoK8GcjxuZzuPebMJZ9nGRURigT8CXzHGvDOZRqqp4Zpi+XdP7OH/dpzhjRONPPb68Bes5/dV6+pZpYKQP0G/CygQkTwRseEI8y2jTxKRIiAB2OFxzAb8DnjcGPPM1DRZTVZ2QiRhIRb6B+08+rGLuGllBg9vL+dkQycPvXKCL2zexzdfODziMfXtvRhj3Lcrm7t56JUTDA7pNwGl5gqfs26MMYMi8jlgK2AFfmGMOSwiDwClxhhX6G8CNhvPVICPAlcBSSLyCeexTxhj9k3VC1D+s1qEX/7NWlJjw1iUEs0leQm8XtbApsfeob6jj9SYMHafaaGlq5+EKBtldR3c+NAbPHbnxVy9NA2AFw/W8OArZYRYhc++dzEAnX2DDA0Z4iJDA/nylFLj8KtGb4x50RhTaIxZZIz5d+exr3mEPMaYbxhj7h/1uCeMMaHGmNUeP/um9BWo83LZoiR3rT41Jpx/fd9S6jv6+NBFWfzkzouxG/hLWT0Az+6pYshuOOOxbUJzt2Mg96FXTnCiroOTDZ1c/+Dr3POr0pl/MUopv+julfPcpktyWJUdz5L0GARIiQlj29F6bl2VxfN7zwHQ0j08S6elq5+4iFAsAvc+tZf6jj6au/qxj/gip5SaTXQLhHlORCjOjMVqESwWYeOSVF4ra+DN8kZq23sBRkzHbO4aIDM+gm/csoxjtR1E2qzctCKDxs4+jIa9UrOS9ujVCBuXpvKb0kq++cJhosNCiI8MHdmj7+4nMSqUW1ZlEhFqZc2CBLbsP8cfD9bQ1jNAfKQtgK1XSnmjPXo1wpWLk7FZLVQ0dHHD8nQy4yJG9OhbuvtJiLQhIly3LJ2UmDBSYsIAaOjoC1SzlVIT0KBXI0SFhbBuURIAH1yTRUJU6Mig73IEvaeUaA16pWYzDXo1xl3rFnJtcRrr8pNIjLLR3DUAwJDd0NozQELUqKCPcdxu6NSgV2o20hq9GuOa4jSuKXbMm0+ItNHS3Y8xhraeAYyBxFHz5VOiwwHt0Ss1W2mPXk0oMcrGkN3Q3jvoLuGM7tHHRoRgs1q0R6/ULKVBryaU6Az1lq5+9+ybxFFBLyKkxIRpj16pWUqDXk3I1Xtv7u4f7tF7mUKZHG2jsVO3P1ZqNtKgVxNKjBzu0bd2ey/dAFPWo69r76Wte+CCf49SapgGvZqQq0zT3NXvnn2T6KVHP1VB/9c/28k//nb/Bf8epdQwnXWjJpTgEfQt3f2Eh1qIsFnHnJccHUZzVx9DdoPVIpN6roaOPk7Ud3K2uZue/iGvz6OUOn/ao1cTirJZsVkt7hq9t948OHr0dsMFXaZw95lmAPoG7bxd0Tjp36OUGkmDXk1IREiICnXMunHuU++Nr9WxLx6s4aM/2cGfDtWM+1y7TrdgC7EQZbOy7Vj9hTdeKQVo6Ub5ITEqjOauAZq7+8dMrXRx73fjnEv/zO4qWrr6yYyP4KVDNfzhQA1RNiufeWIP1y9L41sfWE5qTPiI31F6poVV2XEkRtl49Vg9xhhEJlcGUkoN06BXPiVGOXawbOnqJzsh0us5yR49+vqOXv7JY0A11Cp86folfPLKPH759mkefLmMD//32/z6U+vISXT8vp7+IQ5Xt3H3VfnkJUWx9XAdR2s6KM6Mpb69l5SYMA19pSZJg175lBBp48i5dlq6B8Zsf+Di6tE3dvbxVrmjvv7ruy8lIdJGXEQomfERAHxmwyIuy0/irl+8y+0/2cGTd68jLzmK/VWtDNoNJQsTWJEdB8C2o3W8dKiGR7aX86OPreHmlZkz8GqVCj5ao1c+JUbZaOjoo83LhmYuUWEhRNqsNHT08caJRhIiQ1mXl8TSjFh3yLusyonnqbvX0Tto547H3qG+o5fdZ1oAuHhhAqkx4azMjuOhbSd4ZHs5AIfPtU/Yxuaufqpbe6bg1SoVfDTolU8JkTY6+gaBsdsfeHLNpX/zRCOXL07GMsE0y+LMWJ745KW09Qzw2Sf38M7JJhanRrsvXPK+FRnYjeHr7y8mLzmKsx7XrR2tb3CITY/t4JO/3DXh66hr7+XWR9/iZEPnhOcpFWw06JVPnuHubfsDl+ToMHaeaqK+o4/1i5N9/t7izFi+c9tKdp1u4Y0TjZQsTHDfd8/6fN7516v5myvyWJAYyZnmrnF/z4+2l1NW18mJ+k76BofGPW/PmRb2V7by8zdP+WybUsFEg1755FmumbBHHx1GXbtj1s2VBb6DHuCWVZl86so8AEpyE93HLRZxz8pZmBTJmaZur9ekPVTdxo//UkFmXDhDdsPJhvE/EFylnd/vraajV7dZUPOHBr3yKckj3OPHGYyF4QHZvOSocWfneHP/jUU8csca3r8qw+v9CxIj6egdpHXUHjjGGP75mQMkRtn4we2rASir6xj3eapaehCBrv4hfr+32u/2KTXXadArnzzLNRP16F1TLK/0o2zjKcRq4f2rMgkL8b7lwQLnFMwzzSPr9GeaujlS0869GxezZkE8Votwom78+nt1aw8FqdGsyIrjiXfOev2GoFQw0qBXPvlbo3f16P0t2/hrYVIUAGeaRpZlDp1rA+CiBQmEhVhZmBTJifrxe/TVLT1kxUfw1+sWcLyug12nW6a0nUrNVhr0yidXuSbSZiU8dPyNxjYsSeH2khyuKkiZ0ud39egrR/XoD1W3E2oVCtKiAShMjfHZo89KiOCWVVnEhofw3a3H6B+0T2lbfalt62Xj9/5C+QQfSEpNNQ165VN4qJUom3XC3jxAVnwE37lt5ZTvOhlhs5IaE8aZptFB38aS9Bh3yacwLZrTTV30DoydedPRO0BbzwDZCZFE2Kx86wPL2XW6hQf+cPi82vLb0kp+9c6ZSb+Wd083c7Kxi71nWyf9O5Q6X34FvYjcICLHRaRcRO73cv+DIrLP+VMmIq0e931cRE44fz4+hW1XMyghyjZhfX66LUyKHFGjN8Zw6FwbyzPj3McK0mKwG7zOvHHNuMlyLt66dXUWn9mwiCfeOcuTO/0P7p+8fpInLyDoj9c6Fn7VtfdO+ndMVunpZr7/5+Mz/rwq8HwGvYhYgUeBG4Fi4A4RKfY8xxhznzFmtTFmNfAI8JzzsYnA14FLgbXA10UkATXnZCdEuEMyEBYkjlw0Vd3aQ2v3AMuyPIPeUcLxVqevbnEGfcLwa/jS9Uu4qjCFB144QpdzQdhEuvsHqWjopL1n8lMzj9c6Sku1AQj6Z/dU8cj2crr7fb9WFVz86dGvBcqNMSeNMf3AZuDWCc6/A3jK+efrgZeNMc3GmBbgZeCGC2mwCoyH71jDv39wecCef0FiJLXtve6yzKFqR894eWas+5y85CisFvE6xdLVo8/2+LCyWoR71ufTN2jnnZNNPttwtKYdY6D1AoLe1bbatpm/kHplc8+I/6r5w5+gzwIqPW5XOY+NISILgTxg+/k+Vs1uqTHhJDmnTwbCwqSRA7KHz7VhtQhLM4aDPizESm5SJGVeBmSrW3qwWS3uKaAuJbkJhIdaeL2swWcbXPvtdPcPTWoQt6tvkLPO9geidFPV4nju0bOXVPCb6sHYTcAzxpjx16F7ISL3iEipiJQ2NPj+B6fmnwXOoHcNyB6qbqMgNXrMLKDCtBjK68cGfVVrD5nx4WP23wkPtbIuP4nXT/i+otWh6jb3n9sm6NWX13fywR+/RU3byJ7zCWe7EqNsM166sduN+1vN2ebx9w1SwcmfoK8GcjxuZzuPebOJ4bKN3481xjxmjCkxxpSkpEzt1DwVHBY6p1iebXZshXCwup1lHgOxLgVpMZzxMvOmuqVnRH3e04bCFE41dk24cRo4ykWuLfHbesa/ZOJPXqtg79lWnt5VNeK4ayD2qoJkGjv7GBiauamd9R19DAw5Fohp0M8//gT9LqBARPJExIYjzLeMPklEioAEYIfH4a3AdSKS4ByEvc55TKnzkhhlIzoshLPN3dR39NHY2cfyrNgx5xWmRWM3jOnVV7f2jDuYfFWho3Px2onxv032DQ5xor6DZc4xgfF69M1d/Ty//xwAv9tbNWL17fHaTsJDLZTkJmLM+JddnA6VLcPhrkE///gMemPMIPA5HAF9FHjaGHNYRB4QkVs8Tt0EbDYef7ONMc3At3B8WOwCHnAeU+q8iAgLEiN5ZncVf/2znQCsyBrboy9KjwHgeO3wgGzvwBANHX3j7r+TnxxFVnwErx0fGfTHazv4xpbD9A/aOVHXycCQ4YpFjlW/o/fdcdm86yz9g3buXp/H6aZu9la2Dv++unYK02LIjHds1jaT5RtXfX5JWozPby4q+PhVozfGvGiMKTTGLDLG/Lvz2NeMMVs8zvmGMWbMHHtjzC+MMYudP/87dU1X880/XFvINUtTSY0NY0NhCsu9BH1uUhS2EAvHPWbenBs1h340EWHDkhR2VDSOGGR9fl81v3z7NL9654y7Pn+5cx8fbz36wSE7T+w4w+WLkvj81QWEhVj43Z7hSuXx2k6WpMWQFusI+rq2GQx650ybyxYlUdXSw5Bd9/mZT/RSgmrOuKY4jWuK0yY8J8RqoSA1mqM1w1ekci+WGqdGD3BVQQq/3nmWPWdbWJefBECF8wIlP3yljKsKUogJC2Gl88PFW4/+T4drOdfWy9dvWUZMeCjXFqfxwoFz/L+bi+noHaCxs48l6TGkx858j76ypZuUmDAK0qLpH7JT19475spfKnjpFggq6BSlx44o3bgXS00QbGvzHHvhH6hqdR+raOiiKD2G7v4h/niwhuLMWGIjQhEZOZe+oqGTL27ey+ef2ktechTXLHV8GH3ooixauwd46VCN+xvGkvQYEiJthFrFvXf/eAaH7Dyy7QSbHttBT79/E9nK6zu9ThWtaukhOyGChYmuDeJmtnxzsqGTxs6ZXzugHDToVdBZmhFDfUcfTc5gqW7twSKQHhc+7mMSo2ykxYZxrMYRyANDds40dfHeolTuXLcQgOVZcVgtQmx4qHt17OCQnY/8zw62Hq7jk1fm8fSnL8PqnMK5viCF7IQIvrB5H//09H7AUSN3XVRlorn0Z5q6uO1/dvD9l8t452Sz+5q6vjy87QSfeWL3mBk9VS095CREjrtB3HS7+/FSvrHl/PYVUlNHg14FnSWjBmQPVbexMCmKUOvEf92L0mM56nzM2eZuBoYMi1Oiue+aQtbmJnKds2wUFxFKa7djemVjZz/NXf38601L+cpNxe6tmgFCrRa2fO5K/vmGJQDkJkW670+PC6d2ghr9vzx7gIqGTr7z4RVYxLEZmj/ONHfT3T/EQY85/0N2w7lWR48+Mz4cq0UmvDTjdKhv72OPnx9Waupp0KugU5TumAJ5rLaDzr5B3ipvYmNRqu/HZcRQXt/BwJCdCuf0zEWp0cRFhvL0Zy7jUmftPj4y1F26cfXKM2K9f1tIjLLx9+9ZzBv/spE/37cBcU7ET4+duEdfXt/JTSsyuP2SBRRnxrLrlH9B7+qp7zw5fH5tey+DdkN2QiQhVgtZ8RGcncFtEIbsho6+Qc619Z73lNLN757Va/xOAQ16FXRSYsJIjrZxrLad14430D9kd/fGJ1KcEcvAkOO6sxXOHTDzU6LGnBcXEeqedeMaUE0bJ+hdrBbBFjL8zy0tNpza9l6vV7nq6huksbOfHGeZ5ZLcRPZWtvjcdqGjd4DmLsc3jZ2nhvfuqXKGf7ZzMHpBYiRnZ3AbBM9N4DzHQHypbu3ha1sO84M/H5/wou/KNw16FZSWpMdwrLaDrYdrSYyyjbjw+HiGvwm0U9HQSWpMGLHhY6+RGxcRSlv3yB59Wtz57QOUHhdGd/8QHV52zXQtbnLV09fmJtI7YHdfUWs8rs3KkqPDKD3dwqCzTl/lHIx2fXAsSIqc0UVTngPX+z3WFfjy/a3H6R+009U/xK5TWva5EBr0KigVpcdSVtfBq8fquWZpqnuAdCL5KVGEWoWjNR1UNHSyODXa63nxkR49+rZerBYhKer8gn6iufSuBU2uoHd9SPkq37g+ID64JpPOvkGOOKeYuo67FmotSIykpXuA9t7J78J5PjzXHOyvmvjDyuVQdRu/21fNJy7PxRZi4dXj9dPVvHlBg14FpaL0GHoH7HT0DXJdcbpfjwm1WlicGsPRmnbK6ztZlOI96OMiHDV6Ywx17X2kxoT59UHiaaK59JXOHrgr6FNiwshLjmKXjwFZV33+tosd20u56vRVLT2kxYa5r8Tl3jdohqZYuoJ+UUoUB6pa/boo+3++dIz4iFD+4bpC1uUn8eoxDfoLoUGvgpKrDBNps57XxcqXpsew63QzHb2DLPJSnweIj7AxZDd09g1S197rsz7vjWuqp7eZN5XN3USHhbiv1QtwSW4Cu063YJ9gRevZ5m5iwkMoTIsmNynSXaevaukmx2P7h9xkx+va66OMcrSmfcSOnZPlmqG0viCFlu4Bqlp6ONvUzfr/2s5b5WN3Da1p6+HN8kY+tT6f2PBQNi5J4WRjF6cbdXvlydKgV0GpIC0aq0XYUJgy4QXNRyvKcCyQAlicGuP1nLgIRwC39QxQ295LWuz579PvLt146dGfbe4mJzHSPUMHHAOybT0D7q2OvTnb3M0C5+MuzUvi3VPN/M9rFeyvbHN/OwDHt52V2XH85LWKCXfQ/OrvD/GJ/93ldSC0vL6T3Wf8mwnkGozd4Nw8bn9VKw/84QiVzT08vO3EmPOPOae4XuIsWW0scgykb5/iXn19Ry93/nwnB/0sJ81lGvQqKIWHWnlo02q+dP2S83qc65sAwKJU7z36OGdPu7V7gLr2XncZ5nzbFx8Z6h4o9eQI7JGreF0rd989Nf6VsCqbh3vul+Yn0t47yH++dIyS3AQ+f3WB+zwR4QtXF1DV0jNiL57RKpyrWX+/d+w5//jb/Xz6V3v8KsO4Sjdr8xKxWS089vpJXjlaR2FaNDtPNY/51uBa/7AkzfFBuyApkkUpUe46vT+XffRlcMjO55/ayxsnGnmj3L9rYJTXd3LjQ2+4ZzbNJRr0KmjdvDKT/HHq7ONxXbEq0mYdN8DjnT362rZeOnoHSZtgxe1ELslN5Dellfz3XyrcgWmModLZM/e0IDGSjLhw3q7wHvR2u6Gypcd9gZYbl2fwhasLeP6zV/CrT17qLte4bCxKZUVWHD96tZymzj7uf/YANz38hrv33tzV797P56dvnBpRMqpo6GR/ZSuNnX1+zd5p7R4gItRKVFgISzNjOVDVRl5yFL++ex2RNiu/GDVPvqy2g/TYcPcHqqu9OyqauPTbr7Ds61v50m/3+/UhM54HX3GsOLbI8BYZvuw928LRmvYR+yjNFRr0SnlwzcFflBI9onTiyRVArv1r0mImF/QPb1rDTSsy+M6fjvGlZw5gjKGho4++QfuYoBcRrliczI6TTe7QPVjVxo0PvUF9ey/1HX30D9rdUygjbFbuu7aQVTnxXp/b1as/29zN+v96lc27Kjl8rt29j/+pRsd/b12dSXl9J38pGy6bePbw/dmaoa1nwF3uWp3t2BTua+8vJjk6jI+W5PDCgXPUe5SwjtV2UJg+smz2kZIcVuXEc8WiZD60Jovf7nZc6BwcPfydJ5v8Dv4dFU08+moFt5fkUJwZ6/VblTdNzp58IC4DeaE06JUa5W+vzONjly4Y9/74CBswXGKYaA+diUTYrDxyxxo+dWUez+yuoqyu091Dzk4cu3f+FYuTaO0ecE+bfHLnGY7WtPPb3VVj5t774+qlqazNSyQ/JYof3r4awL3Xz0nngrF7Ny4mIy6cn7x2EnB84/jd3mquWJxETFjIeQf9p9bn8/2PrOK9Sxwrlf/milwG7YbHd5wBHCWV8oZO93UFXArTYnj27y7nB7ev5vsfXcWH1mTxg5fL+Oyv97Du29u4/bF3xv22M9prZQ2EWoVv3rqMrPgI9+6mvrj2TvK1Gd1spEGv1Ch//57F3LF2gqB39ujLXD36SQzGuogI92zIRwReOlTjDnpvgX2586Inb5U3MjBk50+HawF4dneVezfK8wl6EeE396zjD/eu5+aVGSP28T/Z2EWoVchNiuKTV+ax0zmwW3qmhaqWHj58UTZrFib4FfStPQPub0E5iZF8+OJs930Lk6LYUJjC8/urMcZwuqmb/kE7hWneB8Jd7f6PD69gbV4ifz5cy3uLUgmxCG9X+L7uLzhm9aTHhRMeaiUrPpLqlh6/vg00dc7dHr3uR6/UeQoPtWILsbj3q5/M9EpPqTHhXJKbyEsHa7lxRToi3rdUTosNZ3FqNG+WN1KYHkNr9wDXFafx5yN1PL+vGpHhRVH+cpWnQqwWCtOG9/E/1dDFgkTH3jifuDyX/VVt/OdLx8hJjCAi1Mr1y9KpbO7hh9vKaO8d8LqC2KW9Z8BdUvLm+mXpfPm5g5TVdbrf09E9+tHCQqw88clL6RkYIi4ilLPN3bzr535ANa29ZMQ63t+shAh6BoZo6R4gMco24eManaWb+o7hoP/VjtO8eryBX3ziEr+eO1C0R6/UJMRHhDIwZIiyWYmZIOT89b7l6Ryv6+C1sgbSY8PHnRJ65eJkdp1u5nd7qokJD+E/P7ySiFArb5xoJCM23L0oajKWpMW6pzaebOwkL9kxkB1itfCgs1xS2dzDDcvTiQoLoSQ3AWNg39nWCX+vZ+nGm6udG869crSOY7UdWIRxVyV7soVY3L/30vxE9le2jbkovDc17T1kOD8QXfv/+DMg6yrdeK59eK2sge3H6mf9Xvsa9EpNgitgLrQ373LD8gwA9p5tnbD3e/miJHoH7GzZf47rl6WTGGXjxuWOlb8TPc4fSzNiaOjoo6Gjj9NN3SMWjIVYLXz3I6v4jw+tcG+7vConHotAqY/yTWv3gHumkjepseGsyonn5SN1lNV2kJsUdV5rHwAuzUukf8jOXh8fOna7obatl4w4Z4/e+c2putX37KFGLzV61/5Cvp430DTolZoEV51+qoI+PS6cixbEAxPX2S/NT8K128L7V2UCcJuz5n0+9XlvXGsIth+ro3/QTt6oKZlWi3DH2gXukIwOC2FpRuyE+8z3D9rd5ZWJXLs0lX2Vrew63ey+nsD5KMlNRGTkrp3eNHb1MTBkyIgb2aP3NfPGGOOu0dd3OHYdNca4x1T2np3dm65p0Cs1CXHOmTcXMhA72vtWOHr1ntsVjH3eUFZmx5MQGcrlixz746/LT+I6P66n64srYF886Bjk9WcNwsULE9h7tmXci427Fkt5zon35mrn5RebuvonHIgdT2x4KMUZsT7r9K6yiyvo4yJCibJZfQZ9e88gg3ZDTmIEA0OGlu4Bmrr66XGWirRHr1QQcpduJjm10pv3rcgg0mZlZU7chOf92weW8+O/uth9xSyLRXjsrhKuX+bf5m3jca0hcM1eGd2j96YkN5Gu/iG+9Nv9I+bCu7T1OHrBvnr0Rekx7jKKr4HY8Vyal8SesxPv23+u1RX0jucSEbISfE+xbOxylGuKnQvq6tp73b35nMQI9le1ureFno006JWaBFfpZjLbH4wnMz6C/V+/zj3HfDzLs+K4zNmbn2pL0mMYGDLEhIWQHD3xLBRwDCJ/ekM+Lxw4x3u/9xf+Mmo7YXeP3kfQiwjXOr+RjF4s5a+1eY59+w9Wt457Tm2bI9AzPGYnZcVH+ByMdZVtijMcH8K17b3u3UJvXZVFd/8QZXXj70MUaBr0Sk3CVA/Guvi6ru10c9Xp81Oixl0Z7CnEauHLNy7l5fs2EBMeyq93nh1xv79BD3D3Vfncf2MR+X58k/DGtR/QOyfHL9/UtPVis1pI8phKmZ0Q6bNH75pxU5zpeH/qPYL+ltWOsZI9s7hOr0Gv1CRM9WDsbOEqm/hTtvGUmxzFuvxE9o+6VKBrv5z4SN/fDrLiI/jMhkV+fcB4kxhlY2lGLG+cGH+TsnNtvaTHhY94jqyECNp6BuiY4EIsrjn0SzMc709dex+VzT0kR4dRkBpNcrRtVtfpNeiVmoTlWXFkJ0Sw+Dw3TZvthnv05/+6VuXEU9feN2Ke+fn06KfCxqIUdp1uGXFVK0+1bT3ugViX4SmW4/fqXT369NhwEqNs7hr9gsQIRIQ1CxJm9cwbDXqlJuGiBQm8+S8bfc4mmWuKMmK4vSSH9604/4Fd1wZqnr16V+DGhs/MIvyNRWkM2Q2vl3nv1Z9r7SVz1KrjLD8WTTV19pMQGUqI1UJqTJijR9/S7V67sGZBPCcbu2iZpVsYa9ArpdxCrRa+c9vKcS+6MpHijFhCLDLiAuCt3QPEhIUQMkNjD6tz4kmMsnm9SMmQ3TiuHzCqR5/tT4++q4+kaMdU2rTYcKpbe6hp63WvXbh4QQLgex5/oPj17ovIDSJyXETKReT+cc75qIgcEZHDIvJrj+P/5Tx2VEQelskW4JRSs1p4qJWijJgRPfr2ngFiZ6hsA45FXe8pTOHV4/Vj5vY3dfYxaDdkjgr65OgwbFbLhD36xs5+9wBuemw4ZXUdDNmNe83DxQsTSIgMda9BmG18Br2IWIFHgRuBYuAOESkedU4B8GXgCmPMMuCLzuOXA1cAK4HlwCXAhilsv1JqFlmVHc+Byjb3nvltPQMjrn07EzYuTaW1e2BMzfycc+wgPW5k6cZiETLjwznZ2DXuLpZNnX0ku3v0Ye4PEVfpJsRq4YblGbxytM6v/Xa8eW5PFU+XVk7qsb7406NfC5QbY04aY/qBzcCto865G3jUGNMCYIxxfW8yQDhgA8KAUKBuKhqulJp9VuXE09E3yEnnhbxbfWxoNh3WF6QQYhG2jSrfuOfQe1nkdkluIi8fqeNvf7mLM01jL0Le1NXvXleQ6jHTKsfjko83r8ygu39ozFoCfz32+kmvl22cCv4EfRbg+TFT5TzmqRAoFJG3ROQdEbkBwBizA3gVqHH+bDXGHB39BCJyj4iUikhpQ4N/129USs0+q10Dss46va+dK6dDXEQol+Qm8vSuSv7uid18+bkD1LT1uFfFjh6MBfj2h1bw1ZuWsut0Czf88A1ONgwvfhoYstPaPTCiRg8QYhH3CltwbKyWFGXjj5Mo3zR09HGstoMrC5LP+7H+mKoRkhCgAHgPcAfwUxGJF5HFwFIgG8eHw0YRWT/6wcaYx4wxJcaYkpSUlClqklJqpi1KiSbKZuWAs04fiNINOK4SlhEfzon6Tp7bU809j+/mdFMXYSEWEry0J9Rq4VPr89l631WEWIRvvHDEXcZxzaRJih6u0YNjto7VMjzkGGK1cP3ydLYdraOn//zKN2+VO7adWL94evLPn6CvBnI8bmc7j3mqArYYYwaMMaeAMhzB/0HgHWNMpzGmE3gJuOzCm62Umo2sFmF5Vhx7K1sxxtDWPbODsS7XFqfxh3vX88o/bOCRO9ZwsLqNJ3eeJWPUYqnRsuIjuO/aQl4va+DlI44qc4NzDn1S1HCNHrxvPnfzismVb9440UhCZCjLnCtvp5o/Qb8LKBCRPBGxAZuALaPO+T2O3jwikoyjlHMSOAtsEJEQEQnFMRA7pnSjlAoeVxWmcKCqjWd2V9E/ZJ/x0s1o1y1L596NixmymxGllvHcddlClqTF8MAfjtA7MOTe58ZVo0+KDsNqkRH1eZe1eYmkxITxw1dOjLtoazRjDG+WN3D54mQslumZlOgz6I0xg8DngK04QvppY8xhEXlARG5xnrYVaBKRIzhq8l8yxjQBzwAVwEFgP7DfGPPCNLwOpdQscc9V+Vy8MIF//d1BYPhi6oH0xWsK/V4IFmK18M1bl1HV0sPD207Q5Ny50lWjt1qE//jgCj5xeZ7Xxz740dWcbOzkU/+3y68ZOOX1ndS193Hl4umpz4OfNXpjzIvGmEJjzCJjzL87j33NGLPF+WdjjPkHY0yxMWaFMWaz8/iQMebTxpilzvv+YdpeiVJqVgi1Wnj0Yxe5ryMb6B49OML5O7et5M7Lcv06f11+Eh+5OJufvH6SV485Jogkeezm+dFLcsa9QMqVBck8ePtqSs+08Nkn93gN+xN1Hfzgz8fp7BvkjROO+nzAg14ppc5Helw4j3xsDUlRNr+u/zobffXmYlKiw9iy/xw2q4WYMP+3cbh5ZSbfunU5247Vc9fP36W1e3hrhPr2Xu76xbs8vL2cW3/0Js/vP0duUuQFXwpyIhr0SqlpcfmiZEq/es2kLg04G8RFhPIfH14BOHrz57uo/6/XLeSRO9awr7KV2/5nB386VENTZx+feryUtp4B/u0Dy2ntHmB/Zeu0Tat0mZmdhpRS89Jc3/HkvUtSueeq/Am3MJ7I+1dlkhITxud+vZfPPLEHABH46Z0lXFOcxsaiVH7wchl3+VlSmiwZb8lvoJSUlJjS0tJAN0MppabM4JCdXadb2Ha0juLMWD50UfaUP4eI7DbGlHi7T3v0Sik1zUKsFi5blDRtl4D0RWv0SikV5DTolVIqyGnQK6VUkNOgV0qpIKdBr5RSQU6DXimlgpwGvVJKBTkNeqWUCnKzbmWsiDQAZy7gVyQDjVPUnJmmbQ8MbXvgzOX2z7a2LzTGeL1E1awL+gslIqXjLQOe7bTtgaFtD5y53P651HYt3SilVJDToFdKqSAXjEH/WKAbcAG07YGhbQ+cudz+OdP2oKvRK6WUGikYe/RKKaU8aNArpVSQC5qgF5EbROS4iJSLyP2Bbs9ERCRHRF4VkSMiclhEvuA8nigiL4vICed/EwLd1vGIiFVE9orIH5y380Rkp/P9/42I2ALdxvGISLyIPCMix0TkqIhcNlfeexG5z/l35pCIPCUi4bP1vReRX4hIvYgc8jjm9X0Wh4edr+GAiFwUuJaP2/bvOv/OHBCR34lIvMd9X3a2/biIXB+QRk8gKIJeRKzAo8CNQDFwh4gUB7ZVExoE/tEYUwysAz7rbO/9wDZjTAGwzXl7tvoCcNTj9neAB40xi4EW4JMBaZV/HgL+ZIwpAlbheB2z/r0XkSzg80CJMWY5YAU2MXvf+18CN4w6Nt77fCNQ4Py5B/jvGWrjeH7J2La/DCw3xqwEyoAvAzj/7W4Cljkf82NnJs0aQRH0wFqg3Bhz0hjTD2wGbg1wm8ZljKkxxuxx/rkDR9Bk4Wjz/zlP+z/gAwFpoA8ikg3cBPzMeVuAjcAzzlNmc9vjgKuAnwMYY/qNMa3Mkfcex+U/I0QkBIgEapil770x5nWgedTh8d7nW4HHjcM7QLyIZMxIQ73w1nZjzJ+NMYPOm+8Argu/3gpsNsb0GWNOAeU4MmnWCJagzwIqPW5XOY/NeiKSC6wBdgJpxpga5121QFqg2uXDD4F/BuzO20lAq8c/gtn8/ucBDcD/OktPPxORKObAe2+MqQa+B5zFEfBtwG7mznsP47/Pc+3f8N8CLzn/POvbHixBPyeJSDTwLPBFY0y7533GMe911s19FZGbgXpjzO5At2WSQoCLgP82xqwBuhhVppnF730Cjt5jHpAJRDG2vDBnzNb32RcR+QqO8uuTgW6Lv4Il6KuBHI/b2c5js5aIhOII+SeNMc85D9e5vq46/1sfqPZN4ArgFhE5jaNEthFHzTveWU6A2f3+VwFVxpidztvP4Aj+ufDeXwOcMsY0GGMGgOdw/P+YK+89jP8+z4l/wyLyCeBm4K/M8CKkWd/2YAn6XUCBc/aBDcfAyJYAt2lczpr2z4GjxpgfeNy1Bfi4888fB56f6bb5Yoz5sjEm2xiTi+N93m6M+SvgVeA252mzsu0AxphaoFJEljgPXQ0cYQ689zhKNutEJNL5d8jV9jnx3juN9z5vAe5yzr5ZB7R5lHhmBRG5AUfJ8hZjTLfHXVuATSISJiJ5OAaU3w1EG8dljAmKH+B9OEbCK4CvBLo9Ptp6JY6vrAeAfc6f9+GodW8DTgCvAImBbquP1/Ee4A/OP+fj+MtdDvwWCAt0+yZo92qg1Pn+/x5ImCvvPfBN4BhwCPgVEDZb33vgKRxjCQM4vkl9crz3GRAcM+cqgIM4ZhbNtraX46jFu/7N/o/H+V9xtv04cGOg3/vRP7oFglJKBblgKd0opZQahwa9UkoFOQ16pZQKchr0SikV5DTolVIqyGnQK6VUkNOgV0qpIPf/ASqOSOA3BYqSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "9dd673ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "y_pred_list = []\n",
    "model.eval()\n",
    "#Model doesn't need to backpropagate the gradients in test set, so use torch.no_grad()\n",
    "#reduces memory usage and speeds up computation\n",
    "with torch.no_grad():\n",
    "    for xb_test,yb_test  in test_loader:\n",
    "        y_test_pred = model(xb_test)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.detach().numpy())\n",
    "\n",
    "#Takes arrays and makes them list of list for each batch        \n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "#flattens the lists in sequence\n",
    "ytest_pred = list(itertools.chain.from_iterable(y_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "7368f8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.77      0.65       152\n",
      "           1       0.47      0.25      0.33       123\n",
      "\n",
      "    accuracy                           0.54       275\n",
      "   macro avg       0.51      0.51      0.49       275\n",
      "weighted avg       0.52      0.54      0.51       275\n",
      "\n",
      "Confusion Matrix of the Test Set:\n",
      "[[117  35]\n",
      " [ 92  31]]\n",
      "Precision Score :  [0.55980861 0.46969697]\n",
      "Recall Score :  [0.76973684 0.25203252]\n",
      "F1 Score :  [0.64819945 0.32804233]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1370: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got None). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1370: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got None). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1370: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got None). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "#Classification accuracy\n",
    "y_true_test = test_y.values.ravel()\n",
    "print(metrics.classification_report(y_true_test,ytest_pred))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true_test ,ytest_pred)\n",
    "print(\"Confusion Matrix of the Test Set:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"Precision Score : \",precision_score(y_true_test,ytest_pred, pos_label='positive', average=None))\n",
    "print(\"Recall Score : \",recall_score(y_true_test,ytest_pred, pos_label='positive', average=None))\n",
    "print(\"F1 Score : \",f1_score(y_true_test,ytest_pred, pos_label='positive', average=None))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
