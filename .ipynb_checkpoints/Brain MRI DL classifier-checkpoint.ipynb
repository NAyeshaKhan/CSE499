{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 687,
   "id": "31b2d207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1112, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SUB_ID</th>\n",
       "      <th>X</th>\n",
       "      <th>subject</th>\n",
       "      <th>SITE_ID</th>\n",
       "      <th>FILE_ID</th>\n",
       "      <th>DX_GROUP</th>\n",
       "      <th>anat_cnr</th>\n",
       "      <th>anat_efc</th>\n",
       "      <th>anat_fber</th>\n",
       "      <th>anat_fwhm</th>\n",
       "      <th>anat_qi1</th>\n",
       "      <th>anat_snr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>50002</td>\n",
       "      <td>1</td>\n",
       "      <td>50002</td>\n",
       "      <td>PITT</td>\n",
       "      <td>no_filename</td>\n",
       "      <td>1</td>\n",
       "      <td>10.201539</td>\n",
       "      <td>1.194664</td>\n",
       "      <td>16.223458</td>\n",
       "      <td>3.878000</td>\n",
       "      <td>0.152711</td>\n",
       "      <td>12.072452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>50003</td>\n",
       "      <td>2</td>\n",
       "      <td>50003</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050003</td>\n",
       "      <td>1</td>\n",
       "      <td>7.165701</td>\n",
       "      <td>1.126752</td>\n",
       "      <td>10.460008</td>\n",
       "      <td>4.282238</td>\n",
       "      <td>0.161716</td>\n",
       "      <td>9.241155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50004</td>\n",
       "      <td>3</td>\n",
       "      <td>50004</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050004</td>\n",
       "      <td>1</td>\n",
       "      <td>7.698144</td>\n",
       "      <td>1.226218</td>\n",
       "      <td>9.725750</td>\n",
       "      <td>3.881684</td>\n",
       "      <td>0.174186</td>\n",
       "      <td>9.323463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50005</td>\n",
       "      <td>4</td>\n",
       "      <td>50005</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050005</td>\n",
       "      <td>1</td>\n",
       "      <td>9.071807</td>\n",
       "      <td>1.256278</td>\n",
       "      <td>11.198226</td>\n",
       "      <td>3.628667</td>\n",
       "      <td>0.119269</td>\n",
       "      <td>10.814200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50006</td>\n",
       "      <td>5</td>\n",
       "      <td>50006</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050006</td>\n",
       "      <td>1</td>\n",
       "      <td>8.026798</td>\n",
       "      <td>1.407166</td>\n",
       "      <td>6.282055</td>\n",
       "      <td>3.674539</td>\n",
       "      <td>0.130647</td>\n",
       "      <td>10.123574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  SUB_ID  X  subject SITE_ID       FILE_ID  DX_GROUP   anat_cnr  \\\n",
       "0           1   50002  1    50002    PITT   no_filename         1  10.201539   \n",
       "1           2   50003  2    50003    PITT  Pitt_0050003         1   7.165701   \n",
       "2           3   50004  3    50004    PITT  Pitt_0050004         1   7.698144   \n",
       "3           4   50005  4    50005    PITT  Pitt_0050005         1   9.071807   \n",
       "4           5   50006  5    50006    PITT  Pitt_0050006         1   8.026798   \n",
       "\n",
       "   anat_efc  anat_fber  anat_fwhm  anat_qi1   anat_snr  \n",
       "0  1.194664  16.223458   3.878000  0.152711  12.072452  \n",
       "1  1.126752  10.460008   4.282238  0.161716   9.241155  \n",
       "2  1.226218   9.725750   3.881684  0.174186   9.323463  \n",
       "3  1.256278  11.198226   3.628667  0.119269  10.814200  \n",
       "4  1.407166   6.282055   3.674539  0.130647  10.123574  "
      ]
     },
     "execution_count": 687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('Phenotypic_V1_0b_preprocessed1.csv')\n",
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "39caed23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values:\n",
      "Unnamed: 0    0\n",
      "SUB_ID        0\n",
      "X             0\n",
      "subject       0\n",
      "SITE_ID       0\n",
      "FILE_ID       0\n",
      "DX_GROUP      0\n",
      "anat_cnr      0\n",
      "anat_efc      0\n",
      "anat_fber     0\n",
      "anat_fwhm     0\n",
      "anat_qi1      0\n",
      "anat_snr      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Dropping empty columns\n",
    "df['DX_GROUP'].replace(2, 0, inplace=True) #So sigmoid function gives right output. if you replace sigmoid, you can skip this\n",
    "\n",
    "df['anat_cnr'].replace('', np.nan, inplace=True)\n",
    "df['anat_efc'].replace('', np.nan, inplace=True)\n",
    "df['anat_fber'].replace('', np.nan, inplace=True)\n",
    "df['anat_fwhm'].replace('', np.nan, inplace=True)\n",
    "df['anat_qi1'].replace('', np.nan, inplace=True)\n",
    "df['anat_snr'].replace('', np.nan, inplace=True)\n",
    "\n",
    "#Replacing null values in all relevant input columns\n",
    "df.dropna(subset=['anat_cnr','anat_efc', 'anat_fber', 'anat_fwhm', 'anat_qi1', 'anat_snr'], inplace=True)\n",
    "\n",
    "#Verifying number of null rows\n",
    "print(\"Number of null values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "875e967c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training data samples:\n",
      "(824, 6)\n"
     ]
    }
   ],
   "source": [
    "X=df[['anat_cnr','anat_efc', 'anat_fber', 'anat_fwhm', 'anat_qi1', 'anat_snr']]\n",
    "y=df['DX_GROUP']\n",
    "\n",
    "train_x,test_x,train_y,test_y = train_test_split(X,y,random_state=42)\n",
    "print(\"\\nTraining data samples:\")\n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "bc7a453c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled values of Train set \n",
      "\n",
      "[[2.66258512e-01 8.70834515e-01 5.95773557e-02 2.54271309e-01\n",
      "  1.26426844e-01 3.48438215e-03]\n",
      " [2.95043381e-01 8.70250262e-01 6.07201068e-02 1.92902434e-01\n",
      "  1.84607580e-01 2.87736912e-03]\n",
      " [2.21616507e-01 8.72967726e-01 1.99478635e-02 2.96678901e-01\n",
      "  2.40373774e-01 2.92762111e-03]\n",
      " ...\n",
      " [8.61828200e-02 6.96365784e-01 1.05786600e-01 4.53536588e-01\n",
      "  2.43836071e-01 1.95344244e-01]\n",
      " [5.72027934e-02 8.71470631e-01 6.19210410e-03 2.11209629e-01\n",
      "  4.03582689e-01 7.57881642e-04]\n",
      " [1.90426202e-01 9.26341194e-01 1.81483671e-03 6.57822767e-02\n",
      "  9.33983754e-01 1.53730773e-03]]\n",
      "\n",
      "Scaled values of Test set \n",
      "\n",
      "[[0.32057977 0.70368126 0.09093268 0.34956924 0.19662656 0.00928808]\n",
      " [0.1501252  0.29007592 0.37771861 0.44484029 0.42582975 0.81990578]\n",
      " [0.78950843 0.70594588 0.70125689 0.70093313 0.17442246 0.03957116]\n",
      " ...\n",
      " [0.486924   0.73549778 0.03119208 0.28398418 0.15877921 0.02604569]\n",
      " [0.26211649 0.72729547 0.00411507 0.74963734 0.257693   0.01229725]\n",
      " [0.22294218 0.70435568 0.03884201 0.30923219 0.2983811  0.00666926]]\n",
      "\n",
      "Train set Tensors \n",
      "\n",
      "tensor([[2.6626e-01, 8.7083e-01, 5.9577e-02, 2.5427e-01, 1.2643e-01, 3.4844e-03],\n",
      "        [2.9504e-01, 8.7025e-01, 6.0720e-02, 1.9290e-01, 1.8461e-01, 2.8774e-03],\n",
      "        [2.2162e-01, 8.7297e-01, 1.9948e-02, 2.9668e-01, 2.4037e-01, 2.9276e-03],\n",
      "        ...,\n",
      "        [8.6183e-02, 6.9637e-01, 1.0579e-01, 4.5354e-01, 2.4384e-01, 1.9534e-01],\n",
      "        [5.7203e-02, 8.7147e-01, 6.1921e-03, 2.1121e-01, 4.0358e-01, 7.5788e-04],\n",
      "        [1.9043e-01, 9.2634e-01, 1.8148e-03, 6.5782e-02, 9.3398e-01, 1.5373e-03]])\n",
      "tensor([0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,\n",
      "        0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
      "        1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
      "        0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,\n",
      "        0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
      "        1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0.,\n",
      "        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,\n",
      "        0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
      "        1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0.])\n",
      "\n",
      "Test set Tensors \n",
      "\n",
      "tensor([[0.3206, 0.7037, 0.0909, 0.3496, 0.1966, 0.0093],\n",
      "        [0.1501, 0.2901, 0.3777, 0.4448, 0.4258, 0.8199],\n",
      "        [0.7895, 0.7059, 0.7013, 0.7009, 0.1744, 0.0396],\n",
      "        ...,\n",
      "        [0.4869, 0.7355, 0.0312, 0.2840, 0.1588, 0.0260],\n",
      "        [0.2621, 0.7273, 0.0041, 0.7496, 0.2577, 0.0123],\n",
      "        [0.2229, 0.7044, 0.0388, 0.3092, 0.2984, 0.0067]])\n",
      "tensor([1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
      "        1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1.,\n",
      "        0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
      "        1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
      "        0., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import torch\n",
    "\n",
    "#MinMaxscaler is used to scale all the features of Train & Test dataframes\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "x_train = scaler.fit_transform(train_x.values)\n",
    "x_test =  scaler.fit_transform(test_x.values)\n",
    "\n",
    "print(\"Scaled values of Train set \\n\")\n",
    "print(x_train)\n",
    "print(\"\\nScaled values of Test set \\n\")\n",
    "print(x_test)\n",
    "\n",
    "#Train and Test sets are converted into Tensors\n",
    "x_tensor =  torch.from_numpy(x_train).float()\n",
    "y_tensor =  torch.from_numpy(train_y.values.ravel()).float()\n",
    "xtest_tensor =  torch.from_numpy(x_test).float()\n",
    "ytest_tensor =  torch.from_numpy(test_y.values.ravel()).float()\n",
    "\n",
    "print(\"\\nTrain set Tensors \\n\")\n",
    "print(x_tensor)\n",
    "print(y_tensor)\n",
    "print(\"\\nTest set Tensors \\n\")\n",
    "print(xtest_tensor)\n",
    "print(ytest_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "id": "05ac05ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "#Define batch size \n",
    "bs = 64\n",
    "#x_train and y_train are combined to a single TensorDataset (easier to iterate over and slice)\n",
    "y_tensor = y_tensor.unsqueeze(1)\n",
    "train_ds = TensorDataset(x_tensor, y_tensor)\n",
    "#DataLoader is responsible for managing batches, & makes it easier to iterate over batches\n",
    "train_dl = DataLoader(train_ds, batch_size=bs)\n",
    "\n",
    "#For the validation/test dataset\n",
    "ytest_tensor = ytest_tensor.unsqueeze(1)\n",
    "test_ds = TensorDataset(xtest_tensor, ytest_tensor)\n",
    "test_loader = DataLoader(test_ds, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "id": "6cef2adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChurnModel(\n",
      "  (layer_1): Linear(in_features=6, out_features=300, bias=True)\n",
      "  (layer_2): Linear(in_features=300, out_features=75, bias=True)\n",
      "  (layer_out): Linear(in_features=75, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (batchnorm1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm1d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "n_input_dim = train_x.shape[1]\n",
    "#Layer size\n",
    "n_hidden1 = 300  # Number of hidden nodes\n",
    "n_hidden2 = 75\n",
    "n_output =  1   # Number of output nodes = for binary classifier\n",
    "\n",
    "class ChurnModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChurnModel, self).__init__()\n",
    "        self.layer_1 = nn.Linear(n_input_dim, n_hidden1) \n",
    "        self.layer_2 = nn.Linear(n_hidden1, n_hidden2)\n",
    "        self.layer_out = nn.Linear(n_hidden2, n_output) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid() #outputs  probability between 0 and 1\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(n_hidden1)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(n_hidden2)\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.sigmoid(self.layer_out(x))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "model = ChurnModel()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "id": "c190a6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss Computation\n",
    "loss_func = nn.BCELoss()\n",
    "#Optimizer\n",
    "learning_rate = 0.0007\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "epochs = 130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "8535529e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last iteration loss value: 0.20968089997768402\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "train_loss = []\n",
    "for epoch in range(epochs):\n",
    "    #Within each epoch run the subsets of data = batch sizes.\n",
    "    for xb, yb in train_dl:\n",
    "        y_pred = model(xb)            # Forward Propagation\n",
    "        loss = loss_func(y_pred, yb)  # Loss Computation\n",
    "        optimizer.zero_grad()         # Clearing all previous gradients, setting to zero \n",
    "        loss.backward()               # Back Propagation\n",
    "        optimizer.step()              # Updating the parameters \n",
    "    #print(\"Loss in iteration :\"+str(epoch)+\" is: \"+str(loss.item()))\n",
    "    train_loss.append(loss.item())\n",
    "print('Last iteration loss value: '+str(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "id": "a451ce13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "id": "9dd673ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "y_pred_list = []\n",
    "model.eval()\n",
    "#Model doesn't need to backpropagate the gradients in test set, so use torch.no_grad()\n",
    "#reduces memory usage and speeds up computation\n",
    "with torch.no_grad():\n",
    "    for xb_test,yb_test  in test_loader:\n",
    "        y_test_pred = model(xb_test)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.detach().numpy())\n",
    "\n",
    "#Takes arrays and makes them list of list for each batch        \n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "#flattens the lists in sequence\n",
    "ytest_pred = list(itertools.chain.from_iterable(y_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "id": "7368f8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.26      0.37       152\n",
      "           1       0.47      0.82      0.60       123\n",
      "\n",
      "    accuracy                           0.51       275\n",
      "   macro avg       0.56      0.54      0.48       275\n",
      "weighted avg       0.56      0.51      0.47       275\n",
      "\n",
      "Confusion Matrix of the Test Set:\n",
      "[[ 39 113]\n",
      " [ 22 101]]\n",
      "Precision Score :  [0.63934426 0.47196262]\n",
      "Recall Score :  [0.25657895 0.82113821]\n",
      "F1 Score :  [0.36619718 0.59940653]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1370: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got None). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1370: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got None). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1370: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got None). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "#Classification accuracy\n",
    "y_true_test = test_y.values.ravel()\n",
    "print(metrics.classification_report(y_true_test,ytest_pred))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true_test ,ytest_pred)\n",
    "print(\"Confusion Matrix of the Test Set:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"Precision Score : \",precision_score(y_true_test,ytest_pred, pos_label='positive', average=None))\n",
    "print(\"Recall Score : \",recall_score(y_true_test,ytest_pred, pos_label='positive', average=None))\n",
    "print(\"F1 Score : \",f1_score(y_true_test,ytest_pred, pos_label='positive', average=None))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
