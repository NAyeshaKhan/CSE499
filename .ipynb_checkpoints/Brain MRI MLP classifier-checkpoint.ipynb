{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "31b2d207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1112, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SUB_ID</th>\n",
       "      <th>X</th>\n",
       "      <th>subject</th>\n",
       "      <th>SITE_ID</th>\n",
       "      <th>FILE_ID</th>\n",
       "      <th>DX_GROUP</th>\n",
       "      <th>anat_cnr</th>\n",
       "      <th>anat_efc</th>\n",
       "      <th>anat_fber</th>\n",
       "      <th>anat_fwhm</th>\n",
       "      <th>anat_qi1</th>\n",
       "      <th>anat_snr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>50002</td>\n",
       "      <td>1</td>\n",
       "      <td>50002</td>\n",
       "      <td>PITT</td>\n",
       "      <td>no_filename</td>\n",
       "      <td>1</td>\n",
       "      <td>10.201539</td>\n",
       "      <td>1.194664</td>\n",
       "      <td>16.223458</td>\n",
       "      <td>3.878000</td>\n",
       "      <td>0.152711</td>\n",
       "      <td>12.072452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>50003</td>\n",
       "      <td>2</td>\n",
       "      <td>50003</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050003</td>\n",
       "      <td>1</td>\n",
       "      <td>7.165701</td>\n",
       "      <td>1.126752</td>\n",
       "      <td>10.460008</td>\n",
       "      <td>4.282238</td>\n",
       "      <td>0.161716</td>\n",
       "      <td>9.241155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50004</td>\n",
       "      <td>3</td>\n",
       "      <td>50004</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050004</td>\n",
       "      <td>1</td>\n",
       "      <td>7.698144</td>\n",
       "      <td>1.226218</td>\n",
       "      <td>9.725750</td>\n",
       "      <td>3.881684</td>\n",
       "      <td>0.174186</td>\n",
       "      <td>9.323463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50005</td>\n",
       "      <td>4</td>\n",
       "      <td>50005</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050005</td>\n",
       "      <td>1</td>\n",
       "      <td>9.071807</td>\n",
       "      <td>1.256278</td>\n",
       "      <td>11.198226</td>\n",
       "      <td>3.628667</td>\n",
       "      <td>0.119269</td>\n",
       "      <td>10.814200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50006</td>\n",
       "      <td>5</td>\n",
       "      <td>50006</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050006</td>\n",
       "      <td>1</td>\n",
       "      <td>8.026798</td>\n",
       "      <td>1.407166</td>\n",
       "      <td>6.282055</td>\n",
       "      <td>3.674539</td>\n",
       "      <td>0.130647</td>\n",
       "      <td>10.123574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  SUB_ID  X  subject SITE_ID       FILE_ID  DX_GROUP   anat_cnr  \\\n",
       "0           1   50002  1    50002    PITT   no_filename         1  10.201539   \n",
       "1           2   50003  2    50003    PITT  Pitt_0050003         1   7.165701   \n",
       "2           3   50004  3    50004    PITT  Pitt_0050004         1   7.698144   \n",
       "3           4   50005  4    50005    PITT  Pitt_0050005         1   9.071807   \n",
       "4           5   50006  5    50006    PITT  Pitt_0050006         1   8.026798   \n",
       "\n",
       "   anat_efc  anat_fber  anat_fwhm  anat_qi1   anat_snr  \n",
       "0  1.194664  16.223458   3.878000  0.152711  12.072452  \n",
       "1  1.126752  10.460008   4.282238  0.161716   9.241155  \n",
       "2  1.226218   9.725750   3.881684  0.174186   9.323463  \n",
       "3  1.256278  11.198226   3.628667  0.119269  10.814200  \n",
       "4  1.407166   6.282055   3.674539  0.130647  10.123574  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('Phenotypic_V1_0b_preprocessed1.csv')\n",
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "39caed23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values:\n",
      "Unnamed: 0    0\n",
      "SUB_ID        0\n",
      "X             0\n",
      "subject       0\n",
      "SITE_ID       0\n",
      "FILE_ID       0\n",
      "DX_GROUP      0\n",
      "anat_cnr      0\n",
      "anat_efc      0\n",
      "anat_fber     0\n",
      "anat_fwhm     0\n",
      "anat_qi1      0\n",
      "anat_snr      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Dropping empty columns\n",
    "df['DX_GROUP'].replace(2, 0, inplace=True) #So sigmoid function gives right output. if you replace sigmoid, you can skip this\n",
    "\n",
    "df['anat_cnr'].replace('', np.nan, inplace=True)\n",
    "df['anat_efc'].replace('', np.nan, inplace=True)\n",
    "df['anat_fber'].replace('', np.nan, inplace=True)\n",
    "df['anat_fwhm'].replace('', np.nan, inplace=True)\n",
    "df['anat_qi1'].replace('', np.nan, inplace=True)\n",
    "df['anat_snr'].replace('', np.nan, inplace=True)\n",
    "\n",
    "#Replacing null values in all relevant input columns\n",
    "df.dropna(subset=['anat_cnr','anat_efc', 'anat_fber', 'anat_fwhm', 'anat_qi1', 'anat_snr'], inplace=True)\n",
    "\n",
    "#Verifying number of null rows\n",
    "print(\"Number of null values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "875e967c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training data samples:\n",
      "(824, 6)\n"
     ]
    }
   ],
   "source": [
    "X=df[['anat_cnr','anat_efc', 'anat_fber', 'anat_fwhm', 'anat_qi1', 'anat_snr']]\n",
    "y=df['DX_GROUP']\n",
    "\n",
    "train_x,test_x,train_y,test_y = train_test_split(X,y,random_state=42)\n",
    "print(\"\\nTraining data samples:\")\n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "bc7a453c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled values of Train set \n",
      "\n",
      "[[2.66258512e-01 8.70834515e-01 5.95773557e-02 2.54271309e-01\n",
      "  1.26426844e-01 3.48438215e-03]\n",
      " [2.95043381e-01 8.70250262e-01 6.07201068e-02 1.92902434e-01\n",
      "  1.84607580e-01 2.87736912e-03]\n",
      " [2.21616507e-01 8.72967726e-01 1.99478635e-02 2.96678901e-01\n",
      "  2.40373774e-01 2.92762111e-03]\n",
      " ...\n",
      " [8.61828200e-02 6.96365784e-01 1.05786600e-01 4.53536588e-01\n",
      "  2.43836071e-01 1.95344244e-01]\n",
      " [5.72027934e-02 8.71470631e-01 6.19210410e-03 2.11209629e-01\n",
      "  4.03582689e-01 7.57881642e-04]\n",
      " [1.90426202e-01 9.26341194e-01 1.81483671e-03 6.57822767e-02\n",
      "  9.33983754e-01 1.53730773e-03]]\n",
      "\n",
      "Scaled values of Test set \n",
      "\n",
      "[[0.32057977 0.70368126 0.09093268 0.34956924 0.19662656 0.00928808]\n",
      " [0.1501252  0.29007592 0.37771861 0.44484029 0.42582975 0.81990578]\n",
      " [0.78950843 0.70594588 0.70125689 0.70093313 0.17442246 0.03957116]\n",
      " ...\n",
      " [0.486924   0.73549778 0.03119208 0.28398418 0.15877921 0.02604569]\n",
      " [0.26211649 0.72729547 0.00411507 0.74963734 0.257693   0.01229725]\n",
      " [0.22294218 0.70435568 0.03884201 0.30923219 0.2983811  0.00666926]]\n",
      "\n",
      "Train set Tensors \n",
      "\n",
      "tensor([[2.6626e-01, 8.7083e-01, 5.9577e-02, 2.5427e-01, 1.2643e-01, 3.4844e-03],\n",
      "        [2.9504e-01, 8.7025e-01, 6.0720e-02, 1.9290e-01, 1.8461e-01, 2.8774e-03],\n",
      "        [2.2162e-01, 8.7297e-01, 1.9948e-02, 2.9668e-01, 2.4037e-01, 2.9276e-03],\n",
      "        ...,\n",
      "        [8.6183e-02, 6.9637e-01, 1.0579e-01, 4.5354e-01, 2.4384e-01, 1.9534e-01],\n",
      "        [5.7203e-02, 8.7147e-01, 6.1921e-03, 2.1121e-01, 4.0358e-01, 7.5788e-04],\n",
      "        [1.9043e-01, 9.2634e-01, 1.8148e-03, 6.5782e-02, 9.3398e-01, 1.5373e-03]])\n",
      "tensor([0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,\n",
      "        0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
      "        1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
      "        0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,\n",
      "        0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
      "        1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0.,\n",
      "        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,\n",
      "        0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
      "        1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0.])\n",
      "\n",
      "Test set Tensors \n",
      "\n",
      "tensor([[0.3206, 0.7037, 0.0909, 0.3496, 0.1966, 0.0093],\n",
      "        [0.1501, 0.2901, 0.3777, 0.4448, 0.4258, 0.8199],\n",
      "        [0.7895, 0.7059, 0.7013, 0.7009, 0.1744, 0.0396],\n",
      "        ...,\n",
      "        [0.4869, 0.7355, 0.0312, 0.2840, 0.1588, 0.0260],\n",
      "        [0.2621, 0.7273, 0.0041, 0.7496, 0.2577, 0.0123],\n",
      "        [0.2229, 0.7044, 0.0388, 0.3092, 0.2984, 0.0067]])\n",
      "tensor([1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
      "        1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1.,\n",
      "        0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
      "        1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
      "        0., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import torch\n",
    "\n",
    "#MinMaxscaler is used to scale all the features of Train & Test dataframes\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "x_train = scaler.fit_transform(train_x.values)\n",
    "x_test =  scaler.fit_transform(test_x.values)\n",
    "\n",
    "print(\"Scaled values of Train set \\n\")\n",
    "print(x_train)\n",
    "print(\"\\nScaled values of Test set \\n\")\n",
    "print(x_test)\n",
    "\n",
    "#Train and Test sets are converted into Tensors\n",
    "x_tensor =  torch.from_numpy(x_train).float()\n",
    "y_tensor =  torch.from_numpy(train_y.values.ravel()).float()\n",
    "xtest_tensor =  torch.from_numpy(x_test).float()\n",
    "ytest_tensor =  torch.from_numpy(test_y.values.ravel()).float()\n",
    "\n",
    "print(\"\\nTrain set Tensors \\n\")\n",
    "print(x_tensor)\n",
    "print(y_tensor)\n",
    "print(\"\\nTest set Tensors \\n\")\n",
    "print(xtest_tensor)\n",
    "print(ytest_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "05ac05ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "#Define batch size \n",
    "bs = 64\n",
    "#x_train and y_train are combined to a single TensorDataset (easier to iterate over and slice)\n",
    "y_tensor = y_tensor.unsqueeze(1)\n",
    "train_ds = TensorDataset(x_tensor, y_tensor)\n",
    "#DataLoader is responsible for managing batches, & makes it easier to iterate over batches\n",
    "train_dl = DataLoader(train_ds, batch_size=bs)\n",
    "\n",
    "#For the validation/test dataset\n",
    "ytest_tensor = ytest_tensor.unsqueeze(1)\n",
    "test_ds = TensorDataset(xtest_tensor, ytest_tensor)\n",
    "test_loader = DataLoader(test_ds, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "6cef2adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChurnModel(\n",
      "  (layer_1): Linear(in_features=6, out_features=2, bias=True)\n",
      "  (layer_2): Linear(in_features=2, out_features=1, bias=True)\n",
      "  (layer_out): Linear(in_features=1, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (batchnorm1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "n_input_dim = train_x.shape[1]\n",
    "#Layer size\n",
    "n_hidden1 = 2  # Number of hidden nodes\n",
    "n_hidden2 = 1\n",
    "n_output =  1   # Number of output nodes for binary classifier\n",
    "\n",
    "class ChurnModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChurnModel, self).__init__()\n",
    "        self.layer_1 = nn.Linear(n_input_dim, n_hidden1) \n",
    "        self.layer_2 = nn.Linear(n_hidden1, n_hidden2)\n",
    "        self.layer_out = nn.Linear(n_hidden2, n_output) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid() #outputs probability between 0 and 1\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(n_hidden1)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(n_hidden2)\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.sigmoid(self.layer_out(x))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "model = ChurnModel()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c190a6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss Computation\n",
    "loss_func = nn.BCELoss()\n",
    "#Optimizer\n",
    "learning_rate = 0.0007\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "8535529e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last iteration loss value: 0.6926021575927734\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "train_loss = []\n",
    "for epoch in range(epochs):\n",
    "    #Within each epoch run the subsets of data = batch sizes.\n",
    "    for xb, yb in train_dl:\n",
    "        y_pred = model(xb)            # Forward Propagation\n",
    "        loss = loss_func(y_pred, yb)  # Loss Computation\n",
    "        optimizer.zero_grad()         # Clearing all previous gradients, setting to zero \n",
    "        loss.backward()               # Back Propagation\n",
    "        optimizer.step()              # Updating the parameters \n",
    "    #print(\"Loss in iteration :\"+str(epoch)+\" is: \"+str(loss.item()))\n",
    "    train_loss.append(loss.item())\n",
    "print('Last iteration loss value: '+str(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "a451ce13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9dd673ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "y_pred_list = []\n",
    "model.eval()\n",
    "#Model doesn't need to backpropagate the gradients in test set, so use torch.no_grad()\n",
    "#reduces memory usage and speeds up computation\n",
    "with torch.no_grad():\n",
    "    for xb_test,yb_test  in test_loader:\n",
    "        y_test_pred = model(xb_test)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.detach().numpy())\n",
    "\n",
    "#Takes arrays and makes them list of list for each batch        \n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "#flattens the lists in sequence\n",
    "ytest_pred = list(itertools.chain.from_iterable(y_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "7368f8c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.82      0.66       152\n",
      "           1       0.43      0.17      0.24       123\n",
      "\n",
      "    accuracy                           0.53       275\n",
      "   macro avg       0.49      0.49      0.45       275\n",
      "weighted avg       0.49      0.53      0.47       275\n",
      "\n",
      "Confusion Matrix of the Test Set:\n",
      "[[124  28]\n",
      " [102  21]]\n",
      "Precision Score :  [0.54867257 0.42857143]\n",
      "Recall Score :  [0.81578947 0.17073171]\n",
      "F1 Score :  [0.65608466 0.24418605]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1370: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got None). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1370: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got None). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1370: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got None). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "#Classification accuracy\n",
    "y_true_test = test_y.values.ravel()\n",
    "print(metrics.classification_report(y_true_test,ytest_pred))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true_test ,ytest_pred)\n",
    "print(\"Confusion Matrix of the Test Set:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"Precision Score : \",precision_score(y_true_test,ytest_pred, pos_label='positive', average=None))\n",
    "print(\"Recall Score : \",recall_score(y_true_test,ytest_pred, pos_label='positive', average=None))\n",
    "print(\"F1 Score : \",f1_score(y_true_test,ytest_pred, pos_label='positive', average=None))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
