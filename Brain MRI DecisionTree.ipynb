{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "831a7b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv('Phenotypic_V1_0b_preprocessed1.csv')\n",
    "\n",
    "#cnr: CONTRAST TO NOISE RATIO, EFC:Overview of extension, SNR: Signal to Noise Ratio, \n",
    "#qi1: model-free quality index, fwhm:Full Width at Half Maximum, fber:fiber-track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7e88971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SUB_ID</th>\n",
       "      <th>X</th>\n",
       "      <th>subject</th>\n",
       "      <th>SITE_ID</th>\n",
       "      <th>FILE_ID</th>\n",
       "      <th>DX_GROUP</th>\n",
       "      <th>anat_cnr</th>\n",
       "      <th>anat_efc</th>\n",
       "      <th>anat_fber</th>\n",
       "      <th>anat_fwhm</th>\n",
       "      <th>anat_qi1</th>\n",
       "      <th>anat_snr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>50002</td>\n",
       "      <td>1</td>\n",
       "      <td>50002</td>\n",
       "      <td>PITT</td>\n",
       "      <td>no_filename</td>\n",
       "      <td>1</td>\n",
       "      <td>10.201539</td>\n",
       "      <td>1.194664</td>\n",
       "      <td>16.223458</td>\n",
       "      <td>3.878000</td>\n",
       "      <td>0.152711</td>\n",
       "      <td>12.072452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>50003</td>\n",
       "      <td>2</td>\n",
       "      <td>50003</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050003</td>\n",
       "      <td>1</td>\n",
       "      <td>7.165701</td>\n",
       "      <td>1.126752</td>\n",
       "      <td>10.460008</td>\n",
       "      <td>4.282238</td>\n",
       "      <td>0.161716</td>\n",
       "      <td>9.241155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50004</td>\n",
       "      <td>3</td>\n",
       "      <td>50004</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050004</td>\n",
       "      <td>1</td>\n",
       "      <td>7.698144</td>\n",
       "      <td>1.226218</td>\n",
       "      <td>9.725750</td>\n",
       "      <td>3.881684</td>\n",
       "      <td>0.174186</td>\n",
       "      <td>9.323463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50005</td>\n",
       "      <td>4</td>\n",
       "      <td>50005</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050005</td>\n",
       "      <td>1</td>\n",
       "      <td>9.071807</td>\n",
       "      <td>1.256278</td>\n",
       "      <td>11.198226</td>\n",
       "      <td>3.628667</td>\n",
       "      <td>0.119269</td>\n",
       "      <td>10.814200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50006</td>\n",
       "      <td>5</td>\n",
       "      <td>50006</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050006</td>\n",
       "      <td>1</td>\n",
       "      <td>8.026798</td>\n",
       "      <td>1.407166</td>\n",
       "      <td>6.282055</td>\n",
       "      <td>3.674539</td>\n",
       "      <td>0.130647</td>\n",
       "      <td>10.123574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  SUB_ID  X  subject SITE_ID       FILE_ID  DX_GROUP   anat_cnr  \\\n",
       "0           1   50002  1    50002    PITT   no_filename         1  10.201539   \n",
       "1           2   50003  2    50003    PITT  Pitt_0050003         1   7.165701   \n",
       "2           3   50004  3    50004    PITT  Pitt_0050004         1   7.698144   \n",
       "3           4   50005  4    50005    PITT  Pitt_0050005         1   9.071807   \n",
       "4           5   50006  5    50006    PITT  Pitt_0050006         1   8.026798   \n",
       "\n",
       "   anat_efc  anat_fber  anat_fwhm  anat_qi1   anat_snr  \n",
       "0  1.194664  16.223458   3.878000  0.152711  12.072452  \n",
       "1  1.126752  10.460008   4.282238  0.161716   9.241155  \n",
       "2  1.226218   9.725750   3.881684  0.174186   9.323463  \n",
       "3  1.256278  11.198226   3.628667  0.119269  10.814200  \n",
       "4  1.407166   6.282055   3.674539  0.130647  10.123574  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ab0dc53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anat_cnr</th>\n",
       "      <th>anat_efc</th>\n",
       "      <th>anat_fber</th>\n",
       "      <th>anat_fwhm</th>\n",
       "      <th>anat_qi1</th>\n",
       "      <th>anat_snr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.201539</td>\n",
       "      <td>1.194664</td>\n",
       "      <td>16.223458</td>\n",
       "      <td>3.878000</td>\n",
       "      <td>0.152711</td>\n",
       "      <td>12.072452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.165701</td>\n",
       "      <td>1.126752</td>\n",
       "      <td>10.460008</td>\n",
       "      <td>4.282238</td>\n",
       "      <td>0.161716</td>\n",
       "      <td>9.241155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.698144</td>\n",
       "      <td>1.226218</td>\n",
       "      <td>9.725750</td>\n",
       "      <td>3.881684</td>\n",
       "      <td>0.174186</td>\n",
       "      <td>9.323463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.071807</td>\n",
       "      <td>1.256278</td>\n",
       "      <td>11.198226</td>\n",
       "      <td>3.628667</td>\n",
       "      <td>0.119269</td>\n",
       "      <td>10.814200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.026798</td>\n",
       "      <td>1.407166</td>\n",
       "      <td>6.282055</td>\n",
       "      <td>3.674539</td>\n",
       "      <td>0.130647</td>\n",
       "      <td>10.123574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    anat_cnr  anat_efc  anat_fber  anat_fwhm  anat_qi1   anat_snr\n",
       "0  10.201539  1.194664  16.223458   3.878000  0.152711  12.072452\n",
       "1   7.165701  1.126752  10.460008   4.282238  0.161716   9.241155\n",
       "2   7.698144  1.226218   9.725750   3.881684  0.174186   9.323463\n",
       "3   9.071807  1.256278  11.198226   3.628667  0.119269  10.814200\n",
       "4   8.026798  1.407166   6.282055   3.674539  0.130647  10.123574"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(df.columns[[0,1,2,3,4,5,6]],axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1f666c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping null values\n",
    "df=df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b154da2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values:\n",
      "anat_cnr     0\n",
      "anat_efc     0\n",
      "anat_fber    0\n",
      "anat_fwhm    0\n",
      "anat_qi1     0\n",
      "anat_snr     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Checking for null values to fill\n",
    "print(\"Number of null values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "009b2f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anat_cnr</th>\n",
       "      <th>anat_efc</th>\n",
       "      <th>anat_fber</th>\n",
       "      <th>anat_fwhm</th>\n",
       "      <th>anat_qi1</th>\n",
       "      <th>anat_snr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1099.000000</td>\n",
       "      <td>1099.000000</td>\n",
       "      <td>1099.000000</td>\n",
       "      <td>1099.000000</td>\n",
       "      <td>1099.000000</td>\n",
       "      <td>1099.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.641527</td>\n",
       "      <td>2.079628</td>\n",
       "      <td>72.804971</td>\n",
       "      <td>3.558793</td>\n",
       "      <td>0.072209</td>\n",
       "      <td>48.185793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.612932</td>\n",
       "      <td>11.435278</td>\n",
       "      <td>155.033640</td>\n",
       "      <td>0.676312</td>\n",
       "      <td>0.052283</td>\n",
       "      <td>282.736653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>-217.560433</td>\n",
       "      <td>-3.123743</td>\n",
       "      <td>2.533930</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.001400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.613273</td>\n",
       "      <td>0.755764</td>\n",
       "      <td>3.898699</td>\n",
       "      <td>3.088846</td>\n",
       "      <td>0.040015</td>\n",
       "      <td>12.262756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.966648</td>\n",
       "      <td>1.675090</td>\n",
       "      <td>10.341742</td>\n",
       "      <td>3.401205</td>\n",
       "      <td>0.060916</td>\n",
       "      <td>15.601842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.181021</td>\n",
       "      <td>3.197335</td>\n",
       "      <td>86.028008</td>\n",
       "      <td>3.831771</td>\n",
       "      <td>0.093534</td>\n",
       "      <td>21.528386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>51.691800</td>\n",
       "      <td>33.318370</td>\n",
       "      <td>1734.146859</td>\n",
       "      <td>5.938324</td>\n",
       "      <td>0.259048</td>\n",
       "      <td>5957.198529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          anat_cnr     anat_efc    anat_fber    anat_fwhm     anat_qi1  \\\n",
       "count  1099.000000  1099.000000  1099.000000  1099.000000  1099.000000   \n",
       "mean     11.641527     2.079628    72.804971     3.558793     0.072209   \n",
       "std       5.612932    11.435278   155.033640     0.676312     0.052283   \n",
       "min       0.000015  -217.560433    -3.123743     2.533930     0.000451   \n",
       "25%       8.613273     0.755764     3.898699     3.088846     0.040015   \n",
       "50%      10.966648     1.675090    10.341742     3.401205     0.060916   \n",
       "75%      13.181021     3.197335    86.028008     3.831771     0.093534   \n",
       "max      51.691800    33.318370  1734.146859     5.938324     0.259048   \n",
       "\n",
       "          anat_snr  \n",
       "count  1099.000000  \n",
       "mean     48.185793  \n",
       "std     282.736653  \n",
       "min       0.001400  \n",
       "25%      12.262756  \n",
       "50%      15.601842  \n",
       "75%      21.528386  \n",
       "max    5957.198529  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features = np.load(\"features.npz\")['a']\n",
    "y_target = np.load(\"labels.npz\")['a']\n",
    "y_target = np.select([y_target == 1, y_target == 2], [0, 1], y_target)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35530140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anat_cnr : [10.20153877  7.16570147  7.69814438 ...  3.41346894  7.83900677\n",
      " 12.16929687]\n",
      "anat_efc : [1.19466382 1.12675161 1.22621772 ... 1.35823764 1.75436261 2.81835195]\n",
      "anat_fber : [16.22345825 10.4600076   9.72575046 ...  4.33569983 12.27005481\n",
      "  9.27210712]\n",
      "anat_fwhm : [3.8780004  4.28223801 3.88168429 ... 3.32455    3.23217    3.51019   ]\n",
      "anat_qi1 : [0.15271098 0.16171559 0.17418572 ... 0.10948991 0.08396437 0.04430978]\n",
      "anat_snr : [12.07245188  9.24115456  9.32346277 ...  4.93395956 16.4031739\n",
      " 23.56598215]\n"
     ]
    }
   ],
   "source": [
    "#Checking number of unique values and wrong entries like symbols -,?,#,*,etc.\n",
    "for col in df.columns:\n",
    "    print('{} : {}'.format(col,df[col].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dc64176",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X_features, y_target, test_size=0.20, random_state = 42, shuffle = True, # shuffle dataset\n",
    "stratify = y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c536197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=5, min_samples_leaf=75,\n",
       "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=5, min_samples_leaf=75,\n",
       "                       random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_leaf=75,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=DecisionTreeClassifier(criterion=\"entropy\", random_state= 42, splitter='best', max_depth=5, min_samples_leaf= 75)\n",
    "model.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d5d0bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de2a8c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.6451149425287356\n",
      "Test Accuracy: 0.6057142857142858\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy:\",model.score(Xtrain, ytrain))\n",
    "print(\"Test Accuracy:\", model.score(Xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0df42126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy for Decision tree with max_depth 1 = 62.21 %\n",
      "Testing Accuracy for Decision tree with max_depth 1 = 52.57 %\n",
      "Training Accuracy for Decision tree with max_depth 2 = 64.8 %\n",
      "Testing Accuracy for Decision tree with max_depth 2 = 54.29 %\n",
      "Training Accuracy for Decision tree with max_depth 3 = 68.25 %\n",
      "Testing Accuracy for Decision tree with max_depth 3 = 53.14 %\n",
      "Training Accuracy for Decision tree with max_depth 4 = 74.57 %\n",
      "Testing Accuracy for Decision tree with max_depth 4 = 57.14 %\n",
      "Training Accuracy for Decision tree with max_depth 5 = 77.87 %\n",
      "Testing Accuracy for Decision tree with max_depth 5 = 60.0 %\n",
      "Training Accuracy for Decision tree with max_depth 6 = 84.91 %\n",
      "Testing Accuracy for Decision tree with max_depth 6 = 53.71 %\n",
      "Training Accuracy for Decision tree with max_depth 7 = 90.66 %\n",
      "Testing Accuracy for Decision tree with max_depth 7 = 58.86 %\n",
      "Training Accuracy for Decision tree with max_depth 8 = 95.11 %\n",
      "Testing Accuracy for Decision tree with max_depth 8 = 57.14 %\n",
      "Training Accuracy for Decision tree with max_depth 9 = 97.41 %\n",
      "Testing Accuracy for Decision tree with max_depth 9 = 60.0 %\n",
      "Training Accuracy for Decision tree with max_depth 10 = 99.57 %\n",
      "Testing Accuracy for Decision tree with max_depth 10 = 58.29 %\n",
      "Training Accuracy for Decision tree with max_depth 11 = 100.0 %\n",
      "Testing Accuracy for Decision tree with max_depth 11 = 57.71 %\n",
      "Training Accuracy for Decision tree with max_depth 12 = 100.0 %\n",
      "Testing Accuracy for Decision tree with max_depth 12 = 57.71 %\n",
      "Training Accuracy for Decision tree with max_depth 13 = 100.0 %\n",
      "Testing Accuracy for Decision tree with max_depth 13 = 57.71 %\n",
      "Training Accuracy for Decision tree with max_depth 14 = 100.0 %\n",
      "Testing Accuracy for Decision tree with max_depth 14 = 57.71 %\n",
      "test accuracies found = [52.57, 54.29, 53.14, 57.14, 60.0, 53.71, 58.86, 57.14, 60.0, 58.29, 57.71, 57.71, 57.71, 57.71]\n",
      "higest test accuracy for DT = 60.0 and it is for max_depth = 5\n"
     ]
    }
   ],
   "source": [
    "#***no need to run this***\n",
    "\n",
    "# to find the value for max depth\n",
    "from sklearn import metrics\n",
    "test_accuracies = []\n",
    "\n",
    "for i in range(1, 15, 1):\n",
    "  dec_tree = DecisionTreeClassifier(max_depth =i, criterion='entropy', random_state=42)\n",
    "  dec_tree.fit(Xtrain, ytrain)   \n",
    "  dec_tree_train_score = dec_tree.score(Xtrain,ytrain)*100\n",
    "  print(f\"Training Accuracy for Decision tree with max_depth {i} = {round(dec_tree_train_score, 2)} %\")\n",
    "  y_pred_rf = dec_tree.predict(Xtest)\n",
    "  dec_tree  = (metrics.accuracy_score(ytest, y_pred_rf)*100)\n",
    "  print(f\"Testing Accuracy for Decision tree with max_depth {i} = {round(dec_tree, 2)} %\")\n",
    "  test_accuracies.append(round(dec_tree , 2)) ##\n",
    "\n",
    "print(f\"test accuracies found = {test_accuracies}\")\n",
    "best_accuracy = max(test_accuracies)\n",
    "print(f\"higest test accuracy for DT = {best_accuracy} and it is for max_depth = {test_accuracies.index(max(test_accuracies))+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b79dc87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy for Decision tree with min_samples_leaf 1 = 100.0 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 1 = 57.71 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 2 = 98.85 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 2 = 58.29 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 3 = 97.84 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 3 = 58.29 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 4 = 96.41 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 4 = 56.0 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 5 = 95.11 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 5 = 58.29 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 6 = 94.11 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 6 = 56.57 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 7 = 93.82 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 7 = 56.57 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 8 = 92.39 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 8 = 58.29 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 9 = 91.52 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 9 = 56.57 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 10 = 91.24 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 10 = 58.29 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 11 = 89.94 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 11 = 58.29 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 12 = 88.36 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 12 = 53.14 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 13 = 86.64 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 13 = 58.86 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 14 = 86.93 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 14 = 57.14 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 15 = 84.48 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 15 = 58.29 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 16 = 84.63 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 16 = 56.0 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 17 = 84.91 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 17 = 57.14 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 18 = 84.91 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 18 = 58.29 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 19 = 84.77 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 19 = 58.29 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 20 = 81.03 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 20 = 55.43 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 21 = 78.74 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 21 = 52.57 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 22 = 78.45 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 22 = 51.43 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 23 = 78.59 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 23 = 51.43 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 24 = 78.59 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 24 = 51.43 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 25 = 78.45 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 25 = 53.14 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 26 = 78.88 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 26 = 53.14 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 27 = 77.44 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 27 = 53.14 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 28 = 77.16 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 28 = 53.71 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 29 = 77.16 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 29 = 53.14 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 30 = 77.16 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 30 = 50.86 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 31 = 74.71 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 31 = 50.29 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 32 = 74.71 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 32 = 50.29 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 33 = 74.71 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 33 = 50.29 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 34 = 74.71 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 34 = 50.29 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 35 = 74.86 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 35 = 49.71 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 36 = 74.86 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 36 = 49.71 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 37 = 74.86 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 37 = 49.71 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 38 = 73.85 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 38 = 53.14 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 39 = 73.56 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 39 = 52.57 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 40 = 73.42 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 40 = 52.57 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 41 = 73.13 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 41 = 58.29 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 42 = 73.13 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 42 = 58.29 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 43 = 73.13 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 43 = 58.29 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 44 = 73.13 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 44 = 58.29 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 45 = 72.99 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 45 = 57.14 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 46 = 72.99 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 46 = 57.14 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 47 = 72.99 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 47 = 57.14 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 48 = 72.99 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 48 = 57.14 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 49 = 72.99 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 49 = 57.14 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 50 = 72.84 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 50 = 57.14 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 51 = 72.84 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 51 = 57.14 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 52 = 72.84 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 52 = 57.14 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 53 = 72.84 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 53 = 57.71 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 54 = 71.41 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 54 = 60.57 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 55 = 70.26 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 55 = 55.43 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 56 = 70.26 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 56 = 55.43 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 57 = 70.26 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 57 = 55.43 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 58 = 70.26 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 58 = 55.43 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 59 = 70.26 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 59 = 55.43 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy for Decision tree with min_samples_leaf 60 = 70.11 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 60 = 54.29 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 61 = 69.97 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 61 = 54.29 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 62 = 69.97 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 62 = 57.14 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 63 = 67.96 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 63 = 59.43 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 64 = 67.96 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 64 = 59.43 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 65 = 67.96 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 65 = 59.43 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 66 = 67.96 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 66 = 59.43 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 67 = 67.96 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 67 = 59.43 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 68 = 67.96 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 68 = 59.43 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 69 = 67.96 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 69 = 59.43 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 70 = 67.96 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 70 = 59.43 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 71 = 67.96 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 71 = 59.43 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 72 = 67.96 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 72 = 59.43 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 73 = 67.96 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 73 = 59.43 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 74 = 67.82 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 74 = 59.43 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 75 = 64.51 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 75 = 60.57 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 76 = 64.51 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 76 = 60.57 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 77 = 64.51 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 77 = 60.57 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 78 = 64.51 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 78 = 60.57 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 79 = 64.51 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 79 = 60.57 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 80 = 64.51 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 80 = 60.57 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 81 = 64.51 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 81 = 60.57 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 82 = 64.51 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 82 = 60.57 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 83 = 64.51 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 83 = 60.57 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 84 = 64.51 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 84 = 60.57 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 85 = 64.51 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 85 = 60.57 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 86 = 64.51 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 86 = 60.57 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 87 = 64.51 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 87 = 60.57 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 88 = 64.51 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 88 = 60.57 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 89 = 64.51 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 89 = 60.57 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 90 = 64.51 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 90 = 60.57 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 91 = 64.51 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 91 = 60.57 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 92 = 64.51 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 92 = 60.57 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 93 = 64.51 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 93 = 60.57 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 94 = 64.51 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 94 = 60.57 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 95 = 64.51 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 95 = 60.57 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 96 = 64.51 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 96 = 60.57 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 97 = 64.51 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 97 = 60.57 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 98 = 64.51 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 98 = 60.57 %\n",
      "Training Accuracy for Decision tree with min_samples_leaf 99 = 64.51 %\n",
      "Testing Accuracy for Decision tree with min_samples_leaf 99 = 60.57 %\n",
      "test accuracies found = [52.57, 54.29, 53.14, 57.14, 60.0, 53.71, 58.86, 57.14, 60.0, 58.29, 57.71, 57.71, 57.71, 57.71, 57.71, 58.29, 58.29, 56.0, 58.29, 56.57, 56.57, 58.29, 56.57, 58.29, 58.29, 53.14, 58.86, 57.14, 58.29, 56.0, 57.14, 58.29, 58.29, 55.43, 52.57, 51.43, 51.43, 51.43, 53.14, 53.14, 53.14, 53.71, 53.14, 50.86, 50.29, 50.29, 50.29, 50.29, 49.71, 49.71, 49.71, 53.14, 52.57, 52.57, 58.29, 58.29, 58.29, 58.29, 57.14, 57.14, 57.14, 57.14, 57.14, 57.14, 57.14, 57.14, 57.71, 60.57, 55.43, 55.43, 55.43, 55.43, 55.43, 54.29, 54.29, 57.14, 59.43, 59.43, 59.43, 59.43, 59.43, 59.43, 59.43, 59.43, 59.43, 59.43, 59.43, 59.43, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57]\n",
      "higest test accuracy for DT = 60.57 and it is for min_samples_leaf = 68\n"
     ]
    }
   ],
   "source": [
    "#***no need to run this***\n",
    "\n",
    "# to find the value for min_samples_leaf\n",
    "\n",
    "\n",
    "for i in range(1, 100, 1):\n",
    "  dec_tree = DecisionTreeClassifier(min_samples_leaf=i, criterion='entropy', random_state=42)\n",
    "  dec_tree.fit(Xtrain, ytrain)   \n",
    "  dec_tree_train_score = dec_tree.score(Xtrain,ytrain)*100\n",
    "  print(f\"Training Accuracy for Decision tree with min_samples_leaf {i} = {round(dec_tree_train_score, 2)} %\")\n",
    "  y_pred_rf = dec_tree.predict(Xtest)\n",
    "  dec_tree  = (metrics.accuracy_score(ytest, y_pred_rf)*100)\n",
    "  print(f\"Testing Accuracy for Decision tree with min_samples_leaf {i} = {round(dec_tree, 2)} %\")\n",
    "  test_accuracies.append(round(dec_tree , 2))\n",
    "\n",
    "print(f\"test accuracies found = {test_accuracies}\")\n",
    "best_accuracy = max(test_accuracies)\n",
    "print(f\"higest test accuracy for DT = {best_accuracy} and it is for min_samples_leaf = {test_accuracies.index(max(test_accuracies))+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ede40dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy for Decisiion tree with min_samples_split 2 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 2 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 3 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 3 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 4 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 4 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 5 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 5 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 6 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 6 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 7 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 7 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 8 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 8 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 9 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 9 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 10 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 10 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 11 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 11 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 12 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 12 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 13 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 13 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 14 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 14 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 15 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 15 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 16 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 16 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 17 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 17 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 18 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 18 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 19 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 19 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 20 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 20 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 21 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 21 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 22 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 22 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 23 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 23 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 24 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 24 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 25 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 25 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 26 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 26 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 27 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 27 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 28 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 28 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 29 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 29 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 30 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 30 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 31 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 31 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 32 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 32 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 33 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 33 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 34 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 34 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 35 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 35 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 36 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 36 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 37 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 37 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 38 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 38 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 39 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 39 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 40 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 40 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 41 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 41 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 42 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 42 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 43 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 43 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 44 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 44 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 45 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 45 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 46 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 46 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 47 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 47 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 48 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 48 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 49 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 49 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 50 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 50 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 51 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 51 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 52 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 52 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 53 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 53 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 54 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 54 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 55 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 55 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 56 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 56 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 57 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 57 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 58 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 58 = 60.57 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy for Decisiion tree with min_samples_split 59 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 59 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 60 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 60 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 61 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 61 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 62 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 62 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 63 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 63 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 64 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 64 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 65 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 65 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 66 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 66 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 67 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 67 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 68 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 68 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 69 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 69 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 70 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 70 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 71 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 71 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 72 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 72 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 73 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 73 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 74 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 74 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 75 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 75 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 76 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 76 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 77 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 77 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 78 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 78 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 79 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 79 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 80 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 80 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 81 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 81 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 82 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 82 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 83 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 83 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 84 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 84 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 85 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 85 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 86 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 86 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 87 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 87 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 88 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 88 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 89 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 89 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 90 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 90 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 91 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 91 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 92 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 92 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 93 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 93 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 94 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 94 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 95 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 95 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 96 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 96 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 97 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 97 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 98 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 98 = 60.57 %\n",
      "Training Accuracy for Decisiion tree with min_samples_split 99 = 71.41 %\n",
      "Testing Accuracy for Decisiion tree with min_samples_split 99 = 60.57 %\n",
      "test accuracies found = [52.57, 54.29, 53.14, 57.14, 60.0, 53.71, 58.86, 57.14, 60.0, 58.29, 57.71, 57.71, 57.71, 57.71, 57.71, 58.29, 58.29, 56.0, 58.29, 56.57, 56.57, 58.29, 56.57, 58.29, 58.29, 53.14, 58.86, 57.14, 58.29, 56.0, 57.14, 58.29, 58.29, 55.43, 52.57, 51.43, 51.43, 51.43, 53.14, 53.14, 53.14, 53.71, 53.14, 50.86, 50.29, 50.29, 50.29, 50.29, 49.71, 49.71, 49.71, 53.14, 52.57, 52.57, 58.29, 58.29, 58.29, 58.29, 57.14, 57.14, 57.14, 57.14, 57.14, 57.14, 57.14, 57.14, 57.71, 60.57, 55.43, 55.43, 55.43, 55.43, 55.43, 54.29, 54.29, 57.14, 59.43, 59.43, 59.43, 59.43, 59.43, 59.43, 59.43, 59.43, 59.43, 59.43, 59.43, 59.43, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57, 60.57]\n",
      "higest test accuracy for DT = 60.57 and it is for min_samples_split = 68\n"
     ]
    }
   ],
   "source": [
    "#***no need to run this***\n",
    "\n",
    "# to find the value for min_samples_split\n",
    "\n",
    "for i in range(2, 100, 1):\n",
    "  dec_tree = DecisionTreeClassifier(min_samples_split=i, criterion='entropy', random_state=42, max_depth = 5,min_samples_leaf =54 )\n",
    "  dec_tree.fit(Xtrain, ytrain)   \n",
    "  dec_tree_train_score = dec_tree.score(Xtrain,ytrain)*100\n",
    "  print(f\"Training Accuracy for Decision tree with min_samples_split {i} = {round(dec_tree_train_score, 2)} %\")\n",
    "  y_pred_rf = dec_tree.predict(Xtest)\n",
    "  dec_tree  = (metrics.accuracy_score(ytest, y_pred_rf)*100)\n",
    "  print(f\"Testing Accuracy for Decision tree with min_samples_split {i} = {round(dec_tree, 2)} %\")\n",
    "  test_accuracies.append(round(dec_tree , 2))\n",
    "\n",
    "print(f\"test accuracies found = {test_accuracies}\")\n",
    "best_accuracy = max(test_accuracies)\n",
    "print(f\"higest test accuracy for DT = {best_accuracy} and it is for min_samples_split = {test_accuracies.index(max(test_accuracies))+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c0e5d98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1eaa71f41f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(model,\n",
    "                      Xtest,\n",
    "                      ytest,\n",
    "                      values_format='d',\n",
    "                      display_labels=[\"ASD\",\"TD\"], cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dc9fc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.56      0.57        81\n",
      "           1       0.63      0.65      0.64        94\n",
      "\n",
      "    accuracy                           0.61       175\n",
      "   macro avg       0.60      0.60      0.60       175\n",
      "weighted avg       0.60      0.61      0.61       175\n",
      "\n",
      "0.6057142857142858\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(metrics.classification_report(ytest, model.predict(Xtest)))\n",
    "\n",
    "print(accuracy_score(ytest, model.predict(Xtest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55012c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average CV Score:  0.4514285714285714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score, LeaveOneOut \n",
    "\n",
    "k_folds = KFold(n_splits = 5)\n",
    "\n",
    "scores = cross_val_score(model, Xtest, ytest, cv = k_folds) \n",
    "print(\"Average CV Score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b86fe6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average CV Score using LOO:  0.3485714285714286\n"
     ]
    }
   ],
   "source": [
    "loo = LeaveOneOut()\n",
    "scores = cross_val_score(model, Xtest, ytest, cv = loo)\n",
    "print(\"Average CV Score using LOO: \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec4b1772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict probabilities\n",
    "pred_prob = model.predict_proba(Xtest)\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# roc curve for models\n",
    "fpr, tpr, thresh = roc_curve(ytest, pred_prob[:,1], pos_label=1)\n",
    "\n",
    "# roc curve for tpr = fpr \n",
    "random_probs = [0 for i in range(len(ytest))]\n",
    "p_fpr, p_tpr, _ = roc_curve(ytest, random_probs, pos_label=1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "# plot roc curves\n",
    "plt.plot(fpr, tpr, linestyle='--',color='orange', label='Decision Tree')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('ROC',dpi=300)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e044c821",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
